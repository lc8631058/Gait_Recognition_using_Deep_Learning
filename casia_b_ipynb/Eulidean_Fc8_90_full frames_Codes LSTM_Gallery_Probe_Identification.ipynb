{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "generate train data, validation data, and test data\n",
    "\"\"\"\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread\n",
    "from scipy.misc import imsave\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import helper\n",
    "from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gallery length: (93,)\n",
      "gallery shape: (32, 1000)\n",
      "\n",
      "probe length: (93,)\n",
      "probe shape: (31, 1000)\n"
     ]
    }
   ],
   "source": [
    "# get codes\n",
    "gallery_features_batch1 = np.load(open(r'gait_data/fc8_90/fc8_90_gallery_codes', mode='rb'))\n",
    "probe_features_batch1 = np.load(open(r'gait_data/fc8_90/fc8_90_probe_codes', mode='rb'))\n",
    "# feature shape\n",
    "print(\"gallery length: {}\".format(gallery_features_batch1.shape))\n",
    "print(\"gallery shape: {}\".format(gallery_features_batch1[0].shape))\n",
    "print(\"\")\n",
    "print(\"probe length: {}\".format(probe_features_batch1.shape))\n",
    "print(\"probe shape: {}\".format(probe_features_batch1[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gallery_features_batch1_add0 = np.zeros([len(gallery_features_batch1), 43, 1000], dtype=float)\n",
    "probe_features_batch1_add0 = np.zeros([len(probe_features_batch1), 43, 1000], dtype=float)\n",
    "\n",
    "g_seq_length = []\n",
    "p_seq_length = []\n",
    "for ii, (gallery, probe) in enumerate(zip(gallery_features_batch1, probe_features_batch1)):\n",
    "    gallery_length = gallery.shape[0]\n",
    "    probe_length = probe.shape[0]\n",
    "    g_seq_length.append(gallery_length)\n",
    "    p_seq_length.append(probe_length)\n",
    "    \n",
    "    gallery_features_batch1_add0[ii, :gallery_length, :] = gallery\n",
    "    probe_features_batch1_add0[ii, :probe_length, :] = probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_1_target_1 = np.concatenate((gallery_features_batch1_add0, probe_features_batch1_add0), axis=1)\n",
    "target_1 = np.ones([batch_1_target_1.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_1_target_1: (93, 86, 1000)\n",
      "\n",
      "target_1: (93,)\n"
     ]
    }
   ],
   "source": [
    "print(\"batch_1_target_1:\", batch_1_target_1.shape)\n",
    "print(\"\")\n",
    "print(\"target_1:\", target_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target 0 Data\n",
    "We create a same length batch with shuffled data\n",
    "直到检测shuffle的idx没有重叠，函数会返回ok，否则打印error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 90, 79, 44, 41, 16, 38, 52, 31, 36, 78, 51, 73, 49, 25,  7, 12,\n",
       "       57, 62, 17, 80, 55, 48, 74, 14, 89,  6, 40, 42, 37,  5,  0, 81,  9,\n",
       "        2, 75, 43, 58, 54,  4, 32, 77, 34, 56, 82, 88, 76,  8, 61, 53, 23,\n",
       "       72, 15, 35, 70, 68, 50, 29, 60, 67, 20, 30, 66, 11, 69, 71, 84, 85,\n",
       "       18, 64, 47, 27, 92, 39, 87, 19, 10, 46, 45, 22, 33, 59,  1, 86, 83,\n",
       "       13,  3, 24, 65, 91, 63, 21, 26])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(len(gallery_features_batch1_add0))\n",
    "np.random.shuffle(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def exam_shuffle_idx(idx):\n",
    "    x =None\n",
    "    for ii, index in enumerate(idx):\n",
    "        if ii == index:\n",
    "            x ='error'\n",
    "            print(x)\n",
    "            break\n",
    "    if x != 'error':\n",
    "        print(\"ok\")\n",
    "    return None\n",
    "exam_shuffle_idx(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 43, 1000)\n"
     ]
    }
   ],
   "source": [
    "# create shuffled half_probe_features_batch1\n",
    "shuffled_probe_features_batch1 = np.zeros(probe_features_batch1_add0.shape)\n",
    "print(shuffled_probe_features_batch1.shape)\n",
    "for ii, index in enumerate(idx):\n",
    "    shuffled_probe_features_batch1[ii, :, :] = probe_features_batch1_add0[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_1_target_0 = np.concatenate((gallery_features_batch1_add0, shuffled_probe_features_batch1), axis=1)\n",
    "target_0 = np.zeros([batch_1_target_0.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14513677,  0.36747506,  0.29001927, ...,  0.12957594,\n",
       "         0.35101527,  0.3333481 ],\n",
       "       [ 0.11314621,  0.3523095 ,  0.27453646, ...,  0.09355041,\n",
       "         0.36715832,  0.32119063],\n",
       "       [ 0.08449331,  0.32923666,  0.31943917, ...,  0.13022023,\n",
       "         0.36273172,  0.36481997],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1_target_0[0][43:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14513677,  0.36747506,  0.29001927, ...,  0.12957594,\n",
       "         0.35101527,  0.3333481 ],\n",
       "       [ 0.11314621,  0.3523095 ,  0.27453646, ...,  0.09355041,\n",
       "         0.36715832,  0.32119063],\n",
       "       [ 0.08449331,  0.32923666,  0.31943917, ...,  0.13022023,\n",
       "         0.36273172,  0.36481997],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1_target_1[28][43:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 86, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate half_batch_1_target_0 and half_batch_1_target_1 together\n",
    "new_batch_1 = np.concatenate((batch_1_target_1, batch_1_target_0), axis=0)\n",
    "new_batch_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gait_data/fc8_90/ordered_new_batch_1', 'wb') as f:\n",
    "    np.save(f, new_batch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_1_and_0 = np.concatenate((target_1, target_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 78,  31,  59,  42,  68,  28, 180,  93, 162,  24,  49, 135,  47,\n",
       "         7, 182,  40, 167,  43, 116, 169, 104,   6, 181,  62,  84, 145,\n",
       "       138, 161, 185,  16, 105, 140, 121,  45, 110, 141, 125, 164, 152,\n",
       "       132, 143,  71, 174,  46,   5, 112,  32, 156, 124,  76,  60, 160,\n",
       "       113,  27, 147,  91, 111,  38,  29,  26, 114, 102,  70,  33,  12,\n",
       "        10,  54, 165,  57,  25, 131,  92, 158, 144,   0,  82, 126,  17,\n",
       "       146, 119, 148,  58,   4, 100, 133,  19, 170, 150, 115,  21,  67,\n",
       "        94,  99,  48, 177, 101, 108,  98,  73,  83,  95,  20,  13, 106,\n",
       "        34, 153,  14, 123,  18, 171,  81,  36,  22,  86, 134, 139, 184,\n",
       "       151,   3, 129, 179,  97, 127, 107,   2, 157,  37, 172,  23, 178,\n",
       "        96,  69, 149,  39,  77, 154, 103,  90,  44,  55,  65,  53,  11,\n",
       "         9,   8,  56,  85,  35,  51, 166,  41,  52,  75,  89, 175, 173,\n",
       "       142,   1, 176,  30,  79,  64, 168,  61, 120, 128, 130,  63,  80,\n",
       "        50, 163,  15,  74, 117, 155, 183, 109,  66, 118,  88,  72,  87,\n",
       "       122, 159, 136, 137])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle new_half_batch_1 to random order\n",
    "idx2 = np.arange(len(new_batch_1))\n",
    "np.random.shuffle(idx2)\n",
    "idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_new_batch_1 = np.ndarray(new_batch_1.shape, dtype=float)\n",
    "shuffled_target_1_and_0 = np.ndarray(target_1_and_0.shape, dtype=float)\n",
    "for ii, index in enumerate(idx2):\n",
    "    shuffled_new_batch_1[ii, :, :] = new_batch_1[index]\n",
    "    shuffled_target_1_and_0[ii] = target_1_and_0[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gait_data/fc8_90/shuffled_new_batch_1', 'wb') as f:\n",
    "    np.save(f, shuffled_new_batch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_shuffled_new_batch_1_target = np.ndarray([186, 2], dtype=float)\n",
    "for ii, each in enumerate(shuffled_target_1_and_0):\n",
    "    if int(each) == 1:\n",
    "        one_hot_shuffled_new_batch_1_target[ii, :] = 1, 0\n",
    "    elif int(each) == 0:\n",
    "        one_hot_shuffled_new_batch_1_target[ii, :] = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gait_data/fc8_90/one_hot_shuffled_new_batch_1_target', 'wb') as f:\n",
    "    np.save(f, one_hot_shuffled_new_batch_1_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_seq_length = np.array(p_seq_length)\n",
    "shuffled_p_seq_length = np.zeros(p_seq_length.shape, dtype=int)\n",
    "for ii, index in enumerate(idx):\n",
    "    shuffled_p_seq_length[ii] = p_seq_length[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_column1 = np.reshape(np.concatenate([g_seq_length, g_seq_length]), [186, 1])\n",
    "seq_column2 = np.reshape(np.concatenate([g_seq_length, shuffled_p_seq_length]), [186, 1])\n",
    "seq_length = np.concatenate([seq_column1, seq_column2], axis=1)\n",
    "\n",
    "shuffled_seq_length = np.zeros(seq_length.shape, dtype=int)\n",
    "for ii, index in enumerate(idx2):\n",
    "    shuffled_seq_length[ii] = seq_length[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gait_data/fc8_90/shuffled_seq_length', 'wb') as f:\n",
    "    np.save(f, shuffled_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 86, 1000)\n"
     ]
    }
   ],
   "source": [
    "seq_length = np.load(open(r'gait_data/fc8_90/shuffled_seq_length', mode='rb'))\n",
    "shuffled_new_batch_1 = np.load(open(r'gait_data/fc8_90/shuffled_new_batch_1', mode='rb'))\n",
    "one_hot_shuffled_new_batch_1_target = np.load(open(r'gait_data/fc8_90/one_hot_shuffled_new_batch_1_target', mode='rb'))\n",
    "print(shuffled_new_batch_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Train and Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 186\n",
      "every length has : (186, 86, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(\"data length: {}\".format(len(shuffled_new_batch_1)))\n",
    "print(\"every length has : {}\".format(shuffled_new_batch_1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x: (148, 86, 1000)\n",
      "Validation_x: (38, 86, 1000)\n",
      "Train_y: (148, 2)\n",
      "Validation_y: (38, 2)\n",
      "train_seq_length: (148, 2)\n",
      "val_seq_length: (38, 2)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_num = int(split_frac*len(shuffled_new_batch_1))\n",
    "\n",
    "train_x_raw, val_x_raw = shuffled_new_batch_1[:split_num], shuffled_new_batch_1[split_num:]\n",
    "train_y_raw, val_y_raw = one_hot_shuffled_new_batch_1_target[:split_num], one_hot_shuffled_new_batch_1_target[split_num:]\n",
    "train_seq_length, val_seq_length = seq_length[:split_num], seq_length[split_num:]\n",
    "\n",
    "# print size\n",
    "print(\"Train_x: {}\".format(np.array(train_x_raw).shape))\n",
    "print(\"Validation_x: {}\".format(np.array(val_x_raw).shape))\n",
    "print(\"Train_y: {}\".format(np.array(train_y_raw).shape))\n",
    "print(\"Validation_y: {}\".format(np.array(val_y_raw).shape))\n",
    "print(\"train_seq_length: {}\".format(np.array(train_seq_length).shape))\n",
    "print(\"val_seq_length: {}\".format(np.array(val_seq_length).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According_len_get_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def According_len_get_outputs(length_batch_1, length_batch_2, outputs_1, outputs_2):\n",
    "    \"\"\"\n",
    "    length_batch_1 and length_batch_2 should minus one\n",
    "    \"\"\"\n",
    "    new_outputs_1 = np.ndarray([outputs_1.shape[0], outputs_1.shape[2]], dtype=float)\n",
    "    new_outputs_2 = np.ndarray([outputs_2.shape[0], outputs_2.shape[2]], dtype=float)\n",
    "    \n",
    "    for ii, (L1, L2, O1, O2) in enumerate(zip(length_batch_1, length_batch_2, outputs_1, outputs_2)):\n",
    "        new_outputs_1[ii, :] = O1[L1, :]\n",
    "        new_outputs_2[ii, :] = O2[L2, :]\n",
    "        \n",
    "    return new_outputs_1, new_outputs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 1],\n",
    "              [2, 3, 2]])\n",
    "b = np.array([[1, 1, 1],\n",
    "              [4, 1, 1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_eulidean_distance(outputs_1, outputs_2):\n",
    "    distance = np.ndarray([outputs_1.shape[0], 1], dtype=float)\n",
    "    \n",
    "    for ii, (a, b) in enumerate(zip(outputs_1, outputs_2)):\n",
    "        distance[ii, :] = np.sum(np.square(a-b))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(batch_size=20, lstm_size=1000, num_layers=1, learning_rate=0.001, grad_clip=1):\n",
    "    \n",
    "    # reset graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope('inputs_1'):\n",
    "        inputs_1 = tf.placeholder(tf.float32, [None, None, 1000], name=\"inputs_1\")\n",
    "    with tf.name_scope('inputs_2'):\n",
    "        inputs_2 = tf.placeholder(tf.float32, [None, None, 1000], name=\"inputs_2\")\n",
    "    with tf.name_scope('targets'):\n",
    "        target_ = tf.placeholder(tf.float32, [None, 2], name=\"targets\")\n",
    "        \n",
    "    seq_1 = tf.placeholder(tf.float32, (None,), name=\"seq_1\")\n",
    "    seq_2 = tf.placeholder(tf.float32, (None,), name=\"seq_2\")\n",
    "    \n",
    "    new_outputs_1 = tf.placeholder(tf.float32, [None, lstm_size], name=\"new_outputs_1\")\n",
    "    new_outputs_2 = tf.placeholder(tf.float32, [None, lstm_size], name=\"new_outputs_2\")\n",
    "    \n",
    "    distance = tf.placeholder(tf.float32, [None, 1], name='distance')\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "#     seq_length = tf.placeholder(tf.int32, (None, ), name='seq_length')\n",
    "    with tf.variable_scope(\"LSTM\"):\n",
    "#         with tf.name_scope(\"RNN_cells_1\"):\n",
    "            # Your basic LSTM cell\n",
    "        #         lstm = tf.contrib.rnn.LSTMBlockFusedCell(lstm_size, forget_bias=1.0, use_peephole=True)\n",
    "        #         lstm = tf.nn.relu(lstm)\n",
    "        lstm_1 = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "            # Add dropout to the cell\n",
    "        drop_1 = tf.contrib.rnn.DropoutWrapper(lstm_1, output_keep_prob=keep_prob)\n",
    "            # Stack up multiple LSTM layers, for deep learning\n",
    "        cell_1 = tf.contrib.rnn.MultiRNNCell([drop_1] * num_layers)\n",
    "\n",
    "#         with tf.name_scope(\"RNN_init_state_1\"):\n",
    "            # Getting an initial state of all zeros\n",
    "        initial_state_1 = cell_1.zero_state(batch_size, tf.float32)\n",
    "\n",
    "#         with tf.name_scope(\"RNN_forward_1\"):\n",
    "        outputs_1, final_state_1 = tf.nn.dynamic_rnn(cell_1, inputs_1, initial_state=initial_state_1, \n",
    "                                                     sequence_length=seq_1)\n",
    "\n",
    "    with tf.variable_scope(\"LSTM\", reuse=True):\n",
    "#         with tf.name_scope(\"RNN_cells_2\"):\n",
    "            # Your basic LSTM cell\n",
    "    #         lstm = tf.contrib.rnn.LSTMBlockFusedCell(lstm_size, forget_bias=1.0, use_peephole=True)\n",
    "    #         lstm = tf.nn.relu(lstm)\n",
    "        lstm_2 = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "            # Add dropout to the cell\n",
    "        drop_2 = tf.contrib.rnn.DropoutWrapper(lstm_2, output_keep_prob=keep_prob)\n",
    "            # Stack up multiple LSTM layers, for deep learning\n",
    "        cell_2 = tf.contrib.rnn.MultiRNNCell([drop_2] * num_layers)\n",
    "\n",
    "#         with tf.name_scope(\"RNN_init_state_2\"):\n",
    "            # Getting an initial state of all zeros\n",
    "        initial_state_2 = cell_2.zero_state(batch_size, tf.float32)\n",
    "\n",
    "#         with tf.name_scope(\"RNN_forward_2\"):\n",
    "        outputs_2, final_state_2 = tf.nn.dynamic_rnn(cell_2, inputs_2, initial_state=initial_state_2, \n",
    "                                                     sequence_length=seq_2)\n",
    "\n",
    "    with tf.name_scope('predictions'):\n",
    "        # only choose final one\n",
    "#         final_output_concat = tf.concat([outputs_1[:, -1], outputs_2[:, -1]], 1)\n",
    "\n",
    "        # through the According_len_get_outputs\n",
    "        # Eulidean distance\n",
    "        logits = tf.contrib.layers.fully_connected(distance, 2)\n",
    "        predictions = tf.nn.softmax(logits, name='predictions')\n",
    "        tf.summary.histogram('predictions', predictions)\n",
    "        \n",
    "    with tf.name_scope('cost'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target_, logits=logits))\n",
    "        tf.summary.scalar('cost', cost)\n",
    "        \n",
    "    with tf.name_scope('train'):\n",
    "#         tvars = tf.trainable_variables()\n",
    "#         grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip, name='clip')\n",
    "#         train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "#         optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "        \n",
    "    with tf.name_scope('saver'):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    export_nodes = ['inputs_1', 'inputs_2', 'target_', 'initial_state_1', 'initial_state_2', 'outputs_1', 'outputs_2',\n",
    "                    'final_state_1', 'final_state_2', 'keep_prob', 'cost', 'logits', 'predictions', 'optimizer', \n",
    "                    'merged', 'saver', 'learning_rate', 'cell_1', 'cell_2', 'distance', 'seq_1', 'seq_2',\n",
    "                    'new_outputs_1', 'new_outputs_2']\n",
    "    \n",
    "    Graph = collections.namedtuple('Graph', export_nodes)\n",
    "    local_dict = locals()\n",
    "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(data, target, seq_length, batch_size):\n",
    "    n_batches = len(data)//batch_size\n",
    "    data = data[:batch_size * n_batches]\n",
    "    target = target[:batch_size * n_batches]\n",
    "    for ii in range(0, batch_size*n_batches, batch_size):\n",
    "        data_batch = data[ii:ii + batch_size]\n",
    "        target_batch = target[ii:ii + batch_size]\n",
    "        seq_length_batch_1 = seq_length[ii:ii + batch_size, 0]\n",
    "        seq_length_batch_2 = seq_length[ii:ii + batch_size, 1]\n",
    "        \n",
    "        yield data_batch, target_batch, seq_length_batch_1, seq_length_batch_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 28],\n",
       "       [31, 31],\n",
       "       [30, 30],\n",
       "       [33, 33],\n",
       "       [30, 30],\n",
       "       [31, 31],\n",
       "       [30, 32],\n",
       "       [32, 31],\n",
       "       [26, 33],\n",
       "       [32, 32],\n",
       "       [27, 27],\n",
       "       [33, 34],\n",
       "       [32, 32],\n",
       "       [31, 31],\n",
       "       [31, 34],\n",
       "       [32, 32],\n",
       "       [31, 31],\n",
       "       [30, 30],\n",
       "       [33, 30],\n",
       "       [30, 32],\n",
       "       [32, 32],\n",
       "       [35, 35],\n",
       "       [30, 30],\n",
       "       [29, 29],\n",
       "       [31, 31],\n",
       "       [23, 33],\n",
       "       [25, 31],\n",
       "       [30, 32],\n",
       "       [28, 32],\n",
       "       [33, 33],\n",
       "       [30, 32],\n",
       "       [32, 30],\n",
       "       [31, 35],\n",
       "       [25, 25],\n",
       "       [31, 29],\n",
       "       [29, 30],\n",
       "       [32, 31],\n",
       "       [31, 32],\n",
       "       [30, 31],\n",
       "       [31, 33],\n",
       "       [28, 33],\n",
       "       [31, 31],\n",
       "       [31, 27],\n",
       "       [31, 31],\n",
       "       [31, 31],\n",
       "       [30, 31],\n",
       "       [32, 32],\n",
       "       [30, 33],\n",
       "       [31, 31],\n",
       "       [30, 30],\n",
       "       [30, 30],\n",
       "       [31, 30],\n",
       "       [30, 28],\n",
       "       [32, 32],\n",
       "       [29, 32],\n",
       "       [34, 34],\n",
       "       [31, 30],\n",
       "       [33, 33],\n",
       "       [29, 29],\n",
       "       [32, 32],\n",
       "       [34, 25],\n",
       "       [31, 31],\n",
       "       [32, 32],\n",
       "       [36, 36],\n",
       "       [30, 30],\n",
       "       [33, 33],\n",
       "       [29, 29],\n",
       "       [31, 27],\n",
       "       [30, 30],\n",
       "       [31, 31],\n",
       "       [33, 27],\n",
       "       [28, 28],\n",
       "       [30, 30],\n",
       "       [34, 31],\n",
       "       [32, 32],\n",
       "       [32, 32],\n",
       "       [36, 30],\n",
       "       [31, 31],\n",
       "       [29, 30],\n",
       "       [32, 36],\n",
       "       [26, 30],\n",
       "       [29, 29],\n",
       "       [32, 32],\n",
       "       [31, 23],\n",
       "       [32, 32],\n",
       "       [30, 30],\n",
       "       [28, 31],\n",
       "       [30, 30],\n",
       "       [34, 29],\n",
       "       [34, 34],\n",
       "       [31, 31],\n",
       "       [30, 27],\n",
       "       [35, 33],\n",
       "       [29, 29],\n",
       "       [31, 35],\n",
       "       [29, 29],\n",
       "       [32, 31],\n",
       "       [31, 34],\n",
       "       [32, 32],\n",
       "       [35, 35],\n",
       "       [32, 30],\n",
       "       [30, 30],\n",
       "       [31, 31],\n",
       "       [31, 27],\n",
       "       [34, 34],\n",
       "       [30, 31],\n",
       "       [32, 32],\n",
       "       [33, 32],\n",
       "       [31, 31],\n",
       "       [28, 25],\n",
       "       [31, 31],\n",
       "       [30, 30],\n",
       "       [34, 34],\n",
       "       [27, 27],\n",
       "       [34, 27],\n",
       "       [31, 31],\n",
       "       [34, 34],\n",
       "       [29, 29],\n",
       "       [33, 33],\n",
       "       [30, 28],\n",
       "       [27, 33],\n",
       "       [32, 33],\n",
       "       [34, 31],\n",
       "       [32, 32],\n",
       "       [32, 32],\n",
       "       [34, 26],\n",
       "       [29, 29],\n",
       "       [30, 33],\n",
       "       [33, 33],\n",
       "       [33, 32],\n",
       "       [33, 32],\n",
       "       [26, 26],\n",
       "       [28, 29],\n",
       "       [31, 31],\n",
       "       [28, 28],\n",
       "       [31, 35],\n",
       "       [33, 27],\n",
       "       [28, 28],\n",
       "       [32, 32],\n",
       "       [26, 26],\n",
       "       [30, 30],\n",
       "       [29, 29],\n",
       "       [32, 32],\n",
       "       [31, 31],\n",
       "       [29, 29],\n",
       "       [28, 28],\n",
       "       [33, 33],\n",
       "       [31, 31]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x_raw\n",
    "val_x = val_x_raw\n",
    "train_y = train_y_raw\n",
    "val_y = val_y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 86, 1000)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, file_writer, save_string):\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        iteration = 1\n",
    "        mean_val_Acc = 0\n",
    "        mean_val_loss = 0\n",
    "        count_Acc_not_increase_epochs = 0\n",
    "        count_loss_not_decrease_epochs = 0\n",
    "        Last_val_Acc = 0\n",
    "        Last_val_loss = 0\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for train_batch, target_batch, seq_length_batch_1, seq_length_batch_2 \\\n",
    "                             in get_batches(train_x, train_y, train_seq_length, batch_size):\n",
    "                start = time.time()\n",
    "#                 state_1 = sess.run(model.initial_state_1)\n",
    "#                 state_2 = sess.run(model.initial_state_2)\n",
    "#                 print(train_batch[:, :15, :].shape)\n",
    "#                 print(target_batch)\n",
    "    #             print('target: {}'.format(target_batch.shape))\n",
    "                \n",
    "                feed_1 = {\n",
    "                        model.inputs_1: train_batch[:, :43, :],\n",
    "                        model.inputs_2: train_batch[:, 43:, :],  \n",
    "                        model.seq_1: seq_length_batch_1,\n",
    "                        model.seq_2: seq_length_batch_2,\n",
    "                        model.keep_prob: 1\n",
    "                        }\n",
    "            \n",
    "#                 print(model.outputs_1.shape, model.outputs_1[:, -1], model.final_output_concat, \n",
    "#                       model.logits, model.predictions, model.cost)\n",
    "                o_1, o_2 = sess.run([model.outputs_1, model.outputs_2], feed_dict=feed_1)\n",
    "                \n",
    "                real_outputs_1, real_outputs_2 = According_len_get_outputs(\n",
    "                                               seq_length_batch_1 - 1, seq_length_batch_2 - 1, o_1, o_2)\n",
    "            \n",
    "                calculated_distance = calculate_eulidean_distance(real_outputs_1, real_outputs_2)\n",
    "                \n",
    "#                 print(o_1[:, 28], o_2[:, 28])\n",
    "#                 print(real_outputs_1, real_outputs_2)\n",
    "                feed_2 = {\n",
    "                        model.target_: target_batch,\n",
    "#                         model.keep_prob: 1,\n",
    "#                         model.initial_state_1: state_1,\n",
    "#                         model.initial_state_2: state_2,\n",
    "                        model.learning_rate: lr,\n",
    "#                         model.new_outputs_1: real_outputs_1,\n",
    "#                         model.new_outputs_2: real_outputs_2\n",
    "                        model.distance: calculated_distance\n",
    "                        }\n",
    "                \n",
    "                loss, _, logi, pred, summary,  = sess.run(\n",
    "                                [model.cost, model.optimizer, model.logits, model.predictions, model.merged]\n",
    "                                , feed_dict=feed_2)\n",
    "                print(pred)\n",
    "#                 print(logi)\n",
    "#                 print('pred: {}'.format(type(pred)))\n",
    "    #             print('pred: {}'.format(np.count_nonzero(pred)))\n",
    "    #             print('pred: {}'.format(np.sum(pred>0.1)))\n",
    "    #             print('pred: {}'.format(pred.size))\n",
    "    #             print('output: {}'.format(out[1, 39, :]))\n",
    "                \n",
    "                if iteration%5==0:\n",
    "                    end = time.time()\n",
    "#                     acc = calculate_accuracy(sess, pred, target_batch, sq_length)\n",
    "                    print(\"Epoch: {}/{},\".format(e+1, epochs),' ',\n",
    "                          \"Iteration: {},\".format(iteration),' ',\n",
    "                          \"Train loss: {:.3f},\".format(loss),' ',\n",
    "                          \"{:.1f}s /batch.\".format((end-start)/5),' '\n",
    "#                           \"ACCuracy: %{:.3f}\".format(acc)\n",
    "                         )\n",
    "                    \n",
    "                    file_writer.add_summary(summary, iteration)\n",
    "                \n",
    "#                 if iteration%25==0:\n",
    "#                     validation_loss = []\n",
    "#                     validation_Acc = []\n",
    "                    \n",
    "#                     if batch_size >= len(val_x):\n",
    "#                         val_batch_size = 30\n",
    "#                     else: \n",
    "#                         val_batch_size = batch_size\n",
    "                    \n",
    "#                     for val_batch, val_target_batch in get_batches(val_x, val_y, val_batch_size):\n",
    "\n",
    "#                         val_state_1 = sess.run(model.cell_1.zero_state(val_batch_size, tf.float32))\n",
    "#                         val_state_2 = sess.run(model.cell_2.zero_state(val_batch_size, tf.float32))\n",
    "\n",
    "#                         feed = {model.inputs_1: val_batch[:, :15, :],\n",
    "#                                 model.inputs_2: val_batch[:, 15:, :],\n",
    "#                                 model.target_: val_target_batch,\n",
    "#                                 model.keep_prob: 1,\n",
    "#                                 model.initial_state_1: val_state_1,\n",
    "#                                 model.initial_state_2: val_state_2,\n",
    "#                                }\n",
    "\n",
    "#                         val_loss, val_pred = sess.run([model.cost, model.predictions], feed_dict=feed)\n",
    "                        \n",
    "# #                         val_acc = calculate_accuracy(sess, val_pred, val_target_batch, val_sq_length)\n",
    "\n",
    "#                         validation_loss.append(val_loss)\n",
    "                        \n",
    "# #                         validation_Acc.append(val_acc)\n",
    "                        \n",
    "#                     Last_val_Acc = mean_val_Acc\n",
    "#                     Last_val_loss = mean_val_loss\n",
    "                        \n",
    "#                     mean_val_loss = sum(validation_loss)/len(validation_loss)  \n",
    "#                     mean_val_Acc = sum(validation_Acc)/len(validation_Acc)\n",
    "#                     print()\n",
    "#                     print(\"Validation loss: {:.3f},\".format(mean_val_loss), ' ',\n",
    "#                           \"Validation Accuracy: %{:.3f}\".format(mean_val_Acc))\n",
    "#                     print()\n",
    "                    \n",
    "                iteration += 1\n",
    "                \n",
    "            # Early stopping  \n",
    "#             if mean_val_Acc - Last_val_Acc <= -0.3:\n",
    "#                 count_Acc_not_increase_epochs += 1\n",
    "#             if Last_val_loss - mean_val_loss <= -0.01:\n",
    "#                 count_loss_not_decrease_epochs += 1\n",
    "            \n",
    "#             if count_Acc_not_increase_epochs >= 5:\n",
    "#                 break\n",
    "#             if count_loss_not_decrease_epochs >= 5:\n",
    "#                 break\n",
    "                \n",
    "        model.saver.save(sess, r\"{}\".format(save_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: checkpoints_identification: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59136283  0.4086372 ]\n",
      " [ 0.79786444  0.2021355 ]\n",
      " [ 0.92679328  0.0732067 ]\n",
      " [ 0.53299987  0.46700019]\n",
      " [ 0.52313411  0.47686595]\n",
      " [ 0.52908456  0.47091541]\n",
      " [ 0.53580892  0.46419105]\n",
      " [ 0.53222674  0.46777323]\n",
      " [ 0.54456913  0.4554309 ]\n",
      " [ 0.52329391  0.47670603]\n",
      " [ 0.52706289  0.47293711]\n",
      " [ 0.53627473  0.4637253 ]\n",
      " [ 0.53188211  0.46811789]\n",
      " [ 0.52011949  0.47988045]\n",
      " [ 0.53037304  0.46962696]\n",
      " [ 0.53331196  0.46668798]\n",
      " [ 0.53685695  0.46314305]\n",
      " [ 0.80287796  0.19712204]\n",
      " [ 0.54209375  0.45790631]\n",
      " [ 0.5321455   0.46785447]\n",
      " [ 0.53365618  0.46634385]\n",
      " [ 0.52487475  0.47512522]\n",
      " [ 0.52968407  0.47031587]\n",
      " [ 0.52838194  0.47161806]\n",
      " [ 0.52820855  0.47179148]\n",
      " [ 0.58258229  0.41741768]\n",
      " [ 0.53980678  0.46019325]\n",
      " [ 0.53625506  0.463745  ]\n",
      " [ 0.52823573  0.47176427]\n",
      " [ 0.52395821  0.4760417 ]\n",
      " [ 0.55552834  0.44447166]\n",
      " [ 0.53278047  0.46721953]\n",
      " [ 0.56230259  0.43769741]\n",
      " [ 0.52132839  0.47867158]\n",
      " [ 0.53441691  0.46558312]\n",
      " [ 0.54526645  0.45473352]\n",
      " [ 0.52960157  0.47039843]\n",
      " [ 0.53760308  0.46239692]\n",
      " [ 0.53055376  0.46944618]\n",
      " [ 0.53132576  0.46867424]\n",
      " [ 0.53236997  0.46763003]\n",
      " [ 0.59999239  0.40000764]\n",
      " [ 0.53789121  0.46210873]\n",
      " [ 0.53752315  0.46247688]\n",
      " [ 0.52389497  0.476105  ]\n",
      " [ 0.52739418  0.47260582]\n",
      " [ 0.51985443  0.4801456 ]\n",
      " [ 0.53025454  0.46974549]\n",
      " [ 0.52679646  0.47320357]\n",
      " [ 0.53835171  0.46164832]\n",
      " [ 0.61601233  0.38398764]\n",
      " [ 0.53371781  0.46628222]\n",
      " [ 0.52941793  0.47058207]\n",
      " [ 0.52549219  0.47450784]\n",
      " [ 0.53033495  0.46966505]\n",
      " [ 0.53186578  0.46813422]\n",
      " [ 0.54478776  0.45521221]\n",
      " [ 0.52402329  0.47597677]\n",
      " [ 0.52740413  0.47259587]\n",
      " [ 0.52482086  0.47517911]\n",
      " [ 0.5398069   0.46019316]\n",
      " [ 0.5342803   0.46571964]\n",
      " [ 0.52413386  0.47586614]\n",
      " [ 0.54298401  0.45701593]\n",
      " [ 0.52795988  0.47204015]\n",
      " [ 0.5911727   0.4088273 ]\n",
      " [ 0.8028003   0.19719975]\n",
      " [ 0.54228669  0.45771331]\n",
      " [ 0.5994283   0.40057173]\n",
      " [ 0.52820891  0.47179112]\n",
      " [ 0.53131378  0.46868622]\n",
      " [ 0.59480536  0.40519461]\n",
      " [ 0.5426681   0.45733193]\n",
      " [ 0.53104705  0.46895292]\n",
      " [ 0.59828836  0.40171167]\n",
      " [ 0.52263075  0.47736928]\n",
      " [ 0.53800058  0.46199948]\n",
      " [ 0.52563828  0.47436172]\n",
      " [ 0.52462298  0.47537696]\n",
      " [ 0.53238618  0.46761388]\n",
      " [ 0.52751809  0.47248191]\n",
      " [ 0.99284983  0.00715013]\n",
      " [ 0.53606212  0.46393785]\n",
      " [ 0.5705055   0.4294945 ]\n",
      " [ 0.5475511   0.45244884]\n",
      " [ 0.52915871  0.47084126]\n",
      " [ 0.53332531  0.46667466]\n",
      " [ 0.53213376  0.46786618]\n",
      " [ 0.52872157  0.47127837]\n",
      " [ 0.53297198  0.46702802]\n",
      " [ 0.5266875   0.47331253]\n",
      " [ 0.5403465   0.45965347]\n",
      " [ 0.53395993  0.4660401 ]\n",
      " [ 0.52383137  0.47616863]\n",
      " [ 0.53399664  0.46600339]\n",
      " [ 0.53013432  0.46986571]\n",
      " [ 0.53707218  0.46292779]\n",
      " [ 0.52725476  0.47274533]\n",
      " [ 0.52494681  0.47505316]\n",
      " [ 0.54523331  0.45476669]]\n",
      "[[ 0.59109575  0.40890425]\n",
      " [ 0.79742104  0.20257898]\n",
      " [ 0.92647678  0.07352318]\n",
      " [ 0.53282154  0.46717849]\n",
      " [ 0.52297157  0.47702849]\n",
      " [ 0.52891248  0.47108746]\n",
      " [ 0.53562611  0.46437383]\n",
      " [ 0.53204966  0.46795031]\n",
      " [ 0.5443725   0.45562747]\n",
      " [ 0.52313113  0.47686887]\n",
      " [ 0.52689403  0.47310594]\n",
      " [ 0.53609121  0.46390882]\n",
      " [ 0.53170556  0.46829441]\n",
      " [ 0.51996183  0.4800382 ]\n",
      " [ 0.53019893  0.46980113]\n",
      " [ 0.53313315  0.46686682]\n",
      " [ 0.53667253  0.46332753]\n",
      " [ 0.80243462  0.19756536]\n",
      " [ 0.54190105  0.45809898]\n",
      " [ 0.53196853  0.46803141]\n",
      " [ 0.53347683  0.46652323]\n",
      " [ 0.5247094   0.4752906 ]\n",
      " [ 0.52951103  0.47048891]\n",
      " [ 0.52821094  0.471789  ]\n",
      " [ 0.52803785  0.47196212]\n",
      " [ 0.58232796  0.41767201]\n",
      " [ 0.53961766  0.46038231]\n",
      " [ 0.53607154  0.46392843]\n",
      " [ 0.52806503  0.47193497]\n",
      " [ 0.52379441  0.47620568]\n",
      " [ 0.55531472  0.44468528]\n",
      " [ 0.53260249  0.46739751]\n",
      " [ 0.5620786   0.4379214 ]\n",
      " [ 0.52116877  0.47883126]\n",
      " [ 0.53423637  0.46576366]\n",
      " [ 0.5450688   0.45493123]\n",
      " [ 0.52942866  0.47057131]\n",
      " [ 0.53741747  0.46258256]\n",
      " [ 0.53037935  0.46962065]\n",
      " [ 0.5311501   0.46884993]\n",
      " [ 0.53219265  0.46780732]\n",
      " [ 0.59971303  0.40028694]\n",
      " [ 0.53770518  0.46229485]\n",
      " [ 0.53733766  0.4626624 ]\n",
      " [ 0.52373123  0.47626883]\n",
      " [ 0.52722478  0.47277519]\n",
      " [ 0.51969713  0.48030287]\n",
      " [ 0.53008062  0.46991947]\n",
      " [ 0.52662802  0.47337198]\n",
      " [ 0.53816491  0.46183515]\n",
      " [ 0.61571097  0.38428894]\n",
      " [ 0.53353834  0.46646169]\n",
      " [ 0.52924532  0.47075471]\n",
      " [ 0.52532583  0.47467414]\n",
      " [ 0.53016084  0.4698391 ]\n",
      " [ 0.53168923  0.46831071]\n",
      " [ 0.54459083  0.45540911]\n", 
      " [ 0.52385926  0.47614068]\n",
      " [ 0.52723473  0.47276527]\n",
      " [ 0.52465564  0.47534439]\n",
      " [ 0.53961778  0.46038225]\n",
      " [ 0.5341      0.46590003]\n",
      " [ 0.52396971  0.47603029]\n",
      " [ 0.54278994  0.45721003]\n",
      " [ 0.52778959  0.47221041]\n",
      " [ 0.5909059   0.40909407]\n",
      " [ 0.80235696  0.19764309]\n",
      " [ 0.54209369  0.45790634]\n",
      " [ 0.59914976  0.40085027]\n",
      " [ 0.5280382   0.4719618 ]\n",
      " [ 0.53113818  0.46886191]\n",
      " [ 0.59453338  0.40546659]\n",
      " [ 0.54247451  0.45752552]\n",
      " [ 0.53087187  0.46912816]\n",
      " [ 0.59801143  0.40198863]\n",
      " [ 0.52246898  0.47753102]\n",
      " [ 0.53781432  0.46218571]\n",
      " [ 0.52547175  0.47452828]\n",
      " [ 0.52445805  0.47554192]\n",
      " [ 0.53220886  0.4677912 ]\n",
      " [ 0.52734852  0.47265148]\n",
      " [ 0.99278873  0.00721127]\n",
      " [ 0.53587896  0.46412107]\n",
      " [ 0.57026911  0.42973095]\n",
      " [ 0.54734993  0.45265016]\n",
      " [ 0.52898651  0.47101346]\n",
      " [ 0.5331465   0.4668535 ]\n",
      " [ 0.53195685  0.46804315]\n",
      " [ 0.52855009  0.47144994]\n",
      " [ 0.5327937   0.4672063 ]\n",
      " [ 0.52651924  0.47348079]\n",
      " [ 0.5401566   0.45984343]\n",
      " [ 0.5337801   0.46621996]\n",
      " [ 0.52366769  0.47633231]\n",
      " [ 0.5338167   0.46618327]\n",
      " [ 0.52996057  0.47003949]\n",
      " [ 0.53688741  0.46311259]\n",
      " [ 0.5270856   0.47291449]\n",
      " [ 0.52478135  0.47521859]\n",
      " [ 0.54503572  0.45496431]]\n",
      "[[ 0.59082878  0.40917119]\n",
      " [ 0.79697716  0.20302282]\n",
      " [ 0.92615938  0.07384065]\n",
      " [ 0.53264326  0.46735674]\n",
      " [ 0.52280903  0.47719097]\n",
      " [ 0.52874047  0.4712595 ]\n",
      " [ 0.53544343  0.46455657]\n",
      " [ 0.53187263  0.46812737]\n",
      " [ 0.54417598  0.45582399]\n",
      " [ 0.52296835  0.47703165]\n",
      " [ 0.52672523  0.47327477]\n",
      " [ 0.53590775  0.46409228]\n",
      " [ 0.53152907  0.4684709 ]\n",
      " [ 0.51980418  0.48019585]\n",
      " [ 0.53002477  0.46997517]\n",
      " [ 0.53295439  0.46704558]\n",
      " [ 0.53648812  0.46351185]\n",
      " [ 0.80199087  0.19800909]\n",
      " [ 0.54170841  0.45829162]\n",
      " [ 0.53179163  0.46820834]\n",
      " [ 0.53329748  0.46670249]\n",
      " [ 0.52454412  0.47545591]\n",
      " [ 0.52933806  0.47066194]\n",
      " [ 0.52804005  0.47195995]\n",
      " [ 0.5278672   0.47213277]\n",
      " [ 0.58207375  0.41792625]\n",
      " [ 0.53942859  0.46057132]\n",
      " [ 0.53588808  0.46411183]\n",
      " [ 0.52789432  0.47210565]\n",
      " [ 0.52363056  0.47636947]\n",
      " [ 0.55510116  0.44489881]\n",
      " [ 0.53242457  0.4675754 ]\n",
      " [ 0.56185466  0.43814534]\n",
      " [ 0.52100915  0.47899082]\n",
      " [ 0.53405583  0.4659442 ]\n",
      " [ 0.54487121  0.45512885]\n",
      " [ 0.52925581  0.47074419]\n",
      " [ 0.53723192  0.46276814]\n",
      " [ 0.53020495  0.46979502]\n",
      " [ 0.53097451  0.46902552]\n",
      " [ 0.53201538  0.46798462]\n",
      " [ 0.59943384  0.40056613]\n",
      " [ 0.53751916  0.46248084]\n",
      " [ 0.53715217  0.4628478 ]\n",
      " [ 0.5235675   0.47643256]\n",
      " [ 0.52705544  0.47294453]\n",
      " [ 0.51953989  0.48046011]\n",
      " [ 0.52990669  0.47009334]\n",
      " [ 0.52645963  0.47354034]\n",
      " [ 0.53797811  0.46202186]\n",
      " [ 0.61540979  0.38459021]\n",
      " [ 0.53335887  0.46664107]\n",
      " [ 0.52907276  0.47092727]\n",
      " [ 0.5251596   0.47484049]\n",
      " [ 0.52998686  0.47001317]\n",
      " [ 0.5315128   0.46848723]\n",
      " [ 0.54439396  0.45560598]\n",
      " [ 0.52369535  0.47630465]\n",
      " [ 0.5270654   0.47293463]\n",
      " [ 0.52449042  0.47550964]\n",
      " [ 0.53942877  0.46057129]\n",
      " [ 0.53391969  0.46608034]\n",
      " [ 0.52380556  0.47619438]\n",
      " [ 0.54259592  0.45740414]\n",
      " [ 0.5276193   0.47238064]\n",
      " [ 0.59063923  0.40936077]\n",
      " [ 0.8019132   0.19808683]\n",
      " [ 0.54190069  0.45809922]\n",
      " [ 0.59887135  0.40112871]\n",
      " [ 0.52786756  0.47213241]\n",
      " [ 0.53096253  0.46903744]\n",
      " [ 0.59426153  0.4057385 ]\n",
      " [ 0.54228097  0.45771906]\n",
      " [ 0.53069669  0.46930331]\n",
      " [ 0.59773463  0.40226543]\n",
      " [ 0.52230728  0.47769269]\n",
      " [ 0.53762811  0.46237189]\n",
      " [ 0.52530521  0.47469485]\n",
      " [ 0.52429318  0.47570682]\n",
      " [ 0.53203154  0.46796849]\n",
      " [ 0.527179    0.47282103]\n",
      " [ 0.99272716  0.00727287]\n",
      " [ 0.53569579  0.46430418]\n",
      " [ 0.57003278  0.42996722]\n",
      " [ 0.5471487   0.45285133]\n",
      " [ 0.52881438  0.47118562]\n",
      " [ 0.53296769  0.46703228]\n",
      " [ 0.53177994  0.46822006]\n",
      " [ 0.52837867  0.47162142]\n",
      " [ 0.53261548  0.46738452]\n",
      " [ 0.52635103  0.47364897]\n",
      " [ 0.5399667   0.46003333]\n",
      " [ 0.53360027  0.46639976]\n",
      " [ 0.52350408  0.47649595]\n",
      " [ 0.53363687  0.46636316]\n",
      " [ 0.52978688  0.4702132 ]\n",
      " [ 0.53670269  0.46329731]\n",
      " [ 0.52691644  0.47308356]\n",
      " [ 0.52461594  0.47538406]\n",
      " [ 0.54483813  0.45516187]]\n",
      "[[ 0.59056205  0.40943798]\n",
      " [ 0.79653329  0.20346677]\n",
      " [ 0.92584109  0.07415888]\n",
      " [ 0.53246504  0.46753487]\n",
      " [ 0.52264661  0.47735342]\n",
      " [ 0.52856851  0.47143149]\n",
      " [ 0.5352608   0.4647392 ]\n",
      " [ 0.53169566  0.46830431]\n",
      " [ 0.54397964  0.45602041]\n",
      " [ 0.52280563  0.47719431]\n",
      " [ 0.52655655  0.47344351]\n",
      " [ 0.5357244   0.46427566]\n",
      " [ 0.53135264  0.46864727]\n",
      " [ 0.51964658  0.48035344]\n",
      " [ 0.52985078  0.47014919]\n",
      " [ 0.5327757   0.46722424]\n",
      " [ 0.53630388  0.46369615]\n",
      " [ 0.80154705  0.19845296]\n",
      " [ 0.54151583  0.45848408]\n",
      " [ 0.53161484  0.46838519]\n",
      " [ 0.53311831  0.46688172]\n",
      " [ 0.5243789   0.47562113]\n",
      " [ 0.52916521  0.47083488]\n",
      " [ 0.52786922  0.47213078]\n",
      " [ 0.52769667  0.47230333]\n",
      " [ 0.58181971  0.41818029]\n",
      " [ 0.5392397   0.4607603 ]\n",
      " [ 0.53570479  0.46429518]\n",
      " [ 0.52772373  0.47227624]\n",
      " [ 0.52346683  0.47653323]\n",
      " [ 0.55488777  0.4451122 ]\n",
      " [ 0.53224677  0.46775326]\n",
      " [ 0.5616309   0.4383691 ]\n",
      " [ 0.52084959  0.47915035]\n",
      " [ 0.53387541  0.46612459]\n",
      " [ 0.54467368  0.45532629]\n",
      " [ 0.52908301  0.47091696]\n",
      " [ 0.53704643  0.46295354]\n",
      " [ 0.53003067  0.4699693 ]\n",
      " [ 0.53079897  0.46920103]\n",
      " [ 0.53183824  0.46816179]\n",
      " [ 0.59915483  0.40084517]\n",
      " [ 0.53733325  0.46266675]\n",
      " [ 0.53696686  0.46303314]\n",
      " [ 0.52340382  0.47659621]\n",
      " [ 0.52688622  0.47311383]\n",
      " [ 0.51938272  0.48061728]\n",
      " [ 0.52973288  0.47026718]\n",
      " [ 0.52629131  0.47370863]\n",
      " [ 0.53779149  0.46220848]\n",
      " [ 0.61510879  0.38489124]\n",
      " [ 0.53317958  0.46682039]\n",
      " [ 0.52890027  0.4710997 ]\n",
      " [ 0.5249933   0.47500661]\n",
      " [ 0.52981287  0.47018707]\n",
      " [ 0.53133643  0.4686636 ]\n",
      " [ 0.54419726  0.45580277]\n",
      " [ 0.5235315   0.4764685 ]\n",
      " [ 0.52689612  0.47310388]\n",
      " [ 0.52432525  0.47567472]\n",
      " [ 0.53923982  0.46076021]\n",
      " [ 0.53373945  0.46626052]\n",
      " [ 0.52364159  0.47635847]\n",
      " [ 0.54240197  0.457598  ]\n",
      " [ 0.52744919  0.47255081]\n",
      " [ 0.59037274  0.40962726]\n",
      " [ 0.80146927  0.19853066]\n",
      " [ 0.54170793  0.4582921 ]\n",
      " [ 0.59859312  0.40140688]\n",
      " [ 0.52769703  0.47230297]\n",
      " [ 0.53078705  0.46921295]\n",
      " [ 0.59398979  0.40601015]\n",
      " [ 0.5420875   0.45791247]\n",
      " [ 0.53052163  0.46947837]\n",
      " [ 0.597458    0.40254202]\n",
      " [ 0.52214569  0.47785434]\n",
      " [ 0.53744203  0.46255797]\n",
      " [ 0.52513874  0.47486126]\n",
      " [ 0.52412832  0.47587162]\n",
      " [ 0.53185433  0.46814567]\n",
      " [ 0.52700955  0.47299045]\n",
      " [ 0.99266511  0.00733489]\n",
      " [ 0.5355128   0.4644872 ]\n",
      " [ 0.56979662  0.43020338]\n",
      " [ 0.54694766  0.45305234]\n",
      " [ 0.5286423   0.4713577 ]\n",
      " [ 0.53278899  0.46721098]\n",
      " [ 0.53160316  0.46839684]\n",
      " [ 0.52820724  0.47179273]\n",
      " [ 0.53243732  0.46756262]\n",
      " [ 0.52618289  0.47381708]\n",
      " [ 0.53977692  0.46022308]\n",
      " [ 0.53342056  0.46657941]\n",
      " [ 0.52334052  0.47665948]\n",
      " [ 0.5334571   0.46654287]\n",
      " [ 0.52961326  0.4703868 ]\n",
      " [ 0.53651804  0.4634819 ]\n",
      " [ 0.52674741  0.47325256]\n",
      " [ 0.5244506   0.47554937]\n",
      " [ 0.54464066  0.45535928]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 100\n",
    "for lstm_size in [3000]:\n",
    "    for num_layers in [1]:\n",
    "        for lr in [0.0005]:\n",
    "                log_string = 'logs/4/lr={},nl={},ls={},bs={}'.format(lr, num_layers, lstm_size, batch_size)\n",
    "                save_string = 'checkpoints\\lr={}_nl={}_ls={}_bs={}.ckpt'.format(lr, num_layers, lstm_size, batch_size)\n",
    "                \n",
    "                writer = tf.summary.FileWriter(log_string)\n",
    "\n",
    "                model = build_rnn(batch_size=batch_size, lstm_size=lstm_size, \n",
    "                                  num_layers=num_layers, learning_rate=lr, grad_clip=100)\n",
    "\n",
    "                train(model, epochs, writer, save_string)\n",
    "                \n",
    "                print(' ')\n",
    "                print(' ')\n",
    "                print(\"leraning_rate={},num_layers={},lstm_size={},batch_size={} finished, saved\".format(lr, num_layers, lstm_size, batch_size))\n",
    "                print(' ')\n",
    "                print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
