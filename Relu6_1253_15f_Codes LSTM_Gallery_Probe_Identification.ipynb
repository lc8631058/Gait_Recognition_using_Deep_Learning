{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "generate train data, validation data, and test data\n",
    "\"\"\"\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread\n",
    "from scipy.misc import imsave\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import helper\n",
    "from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gallery length: (1253,)\n",
      "gallery shape: (32, 4096)\n",
      "\n",
      "probe length: (1253,)\n",
      "probe shape: (31, 4096)\n"
     ]
    }
   ],
   "source": [
    "# get codes\n",
    "gallery_features_batch1 = np.load(open(r'gait_data/gallery_codes_batch_1', mode='rb'))\n",
    "probe_features_batch1 = np.load(open(r'gait_data/probe_codes_batch_1', mode='rb'))\n",
    "# feature shape\n",
    "print(\"gallery length: {}\".format(gallery_features_batch1.shape))\n",
    "print(\"gallery shape: {}\".format(gallery_features_batch1[0].shape))\n",
    "print(\"\")\n",
    "print(\"probe length: {}\".format(probe_features_batch1.shape))\n",
    "print(\"probe shape: {}\".format(probe_features_batch1[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut Raw Data to 15 Frames". 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_gallery_features_batch1 = np.ndarray([len(gallery_features_batch1), 15, 4096], dtype=float)\n",
    "half_probe_features_batch1 = np.ndarray([len(probe_features_batch1), 15, 4096], dtype=float)\n",
    "\n",
    "for ii, (gallery, probe) in enumerate(zip(gallery_features_batch1, probe_features_batch1)):\n",
    "    half_gallery_features_batch1[ii, :, :] = gallery[:15] \n",
    "    half_probe_features_batch1[ii, :, :] = probe[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1253, 15, 4096)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_gallery_features_batch1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_batch_1_target_1 = np.concatenate((half_gallery_features_batch1, half_probe_features_batch1), axis=1)\n",
    "target_1 = np.ones([half_batch_1_target_1.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "half_batch_1_target_1: (1253, 30, 4096)\n",
      "\n",
      "target_1: (1253,)\n"
     ]
    }
   ],
   "source": [
    "print(\"half_batch_1_target_1:\", half_batch_1_target_1.shape)\n",
    "print(\"\")\n",
    "print(\"target_1:\", target_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target 0 Data\n",
    "We create a same length batch with shuffled data\n",
    "直到检测shuffle的idx没有重叠，函数会返回ok，否则打印error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 326,  246,   46, ..., 1158,  670,  851])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(len(half_gallery_features_batch1))\n",
    "np.random.shuffle(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def exam_shuffle_idx(idx):\n",
    "    x =None\n",
    "    for ii, index in enumerate(idx):\n",
    "        if ii == index:\n",
    "            x ='error'\n",
    "            print(x)\n",
    "            break\n",
    "    if x != 'error':\n",
    "        print(\"ok\")\n",
    "    return None\n",
    "exam_shuffle_idx(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create shuffled half_probe_features_batch1\n",
    "shuffled_half_probe_features_batch1 = np.zeros(half_probe_features_batch1.shape)\n",
    "for ii, index in enumerate(idx):\n",
    "    shuffled_half_probe_features_batch1[ii, :, :] = half_probe_features_batch1[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_batch_1_target_0 = np.concatenate((half_gallery_features_batch1, shuffled_half_probe_features_batch1), axis=1)\n",
    "target_0 = np.zeros([half_batch_1_target_0.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03078302,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.03606888,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.00653661,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.02493687,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_batch_1_target_0[0, 15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03078302,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.03606888,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.00653661,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.02493687,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_batch_1_target_1[326, 15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2506, 30, 4096)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate half_batch_1_target_0 and half_batch_1_target_1 together\n",
    "new_half_batch_1 = np.concatenate((half_batch_1_target_1, half_batch_1_target_0), axis=0)\n",
    "new_half_batch_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gait_data/ordered_new_half_batch_1', 'wb') as f:\n",
    "    np.save(f, new_half_batch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.01815505,  0.02952662, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.01808102,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.01243681,  0.        , ...,  0.        ,\n",
       "         0.00709434,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.00118079,  0.00652072],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_1_and_0 = np.concatenate((target_1, target_0))\n",
    "new_half_batch_1[2385]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2385,  843, 1290, ..., 1428,  515,  416])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle new_half_batch_1 to random order\n",
    "idx2 = np.arange(len(new_half_batch_1))\n",
    "np.random.shuffle(idx2)\n",
    "idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_new_half_batch_1 = np.ndarray(new_half_batch_1.shape, dtype=float)\n",
    "shuffled_target_1_and_0 = np.ndarray(target_1_and_0.shape, dtype=float)\n",
    "for ii, index in enumerate(idx2):\n",
    "    shuffled_new_half_batch_1[ii, :, :] = new_half_batch_1[index]\n",
    "    shuffled_target_1_and_0[ii] = target_1_and_0[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.01815505,  0.02952662, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.01808102,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.01243681,  0.        , ...,  0.        ,\n",
       "         0.00709434,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.00118079,  0.00652072],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_new_half_batch_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gait_data/shuffled_new_half_batch_1', 'wb') as f:\n",
    "    np.save(f, shuffled_new_half_batch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_shuffled_new_half_batch_1_target = np.ndarray([shuffled_new_half_batch_1_target.shape[0], 2], dtype=float)\n",
    "for ii, each in enumerate(shuffled_new_half_batch_1_target):\n",
    "    if int(each) == 1:\n",
    "        one_hot_shuffled_new_half_batch_1_target[ii, :] = 1, 0\n",
    "    elif int(each) == 0:\n",
    "        one_hot_shuffled_new_half_batch_1_target[ii, :] = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gait_data/shuffled_new_half_batch_1_target', 'wb') as f:\n",
    "    np.save(f, one_hot_shuffled_new_half_batch_1_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2506, 30, 4096)\n"
     ]
    }
   ],
   "source": [
    "shuffled_new_half_batch_1 = np.load(open(r'gait_data/shuffled_new_half_batch_1', mode='rb'))\n",
    "shuffled_new_half_batch_1_target = np.load(open(r'gait_data/shuffled_new_half_batch_1_target', mode='rb'))\n",
    "print(shuffled_new_half_batch_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Train and Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 2506\n",
      "every length has : (2506, 30, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(\"data length: {}\".format(len(shuffled_new_half_batch_1)))\n",
    "print(\"every length has : {}\".format(shuffled_new_half_batch_1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x: (2004, 30, 4096)\n",
      "Validation_x: (502, 30, 4096)\n",
      "Train_y: (2004, 2)\n",
      "Validation_y: (502, 2)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_num = int(split_frac*len(shuffled_new_half_batch_1))\n",
    "\n",
    "train_x_raw, val_x_raw = shuffled_new_half_batch_1[:split_num], shuffled_new_half_batch_1[split_num:]\n",
    "train_y_raw, val_y_raw = shuffled_new_half_batch_1_target[:split_num], shuffled_new_half_batch_1_target[split_num:]\n",
    "\n",
    "# print size\n",
    "print(\"Train_x: {}\".format(np.array(train_x_raw).shape))\n",
    "print(\"Validation_x: {}\".format(np.array(val_x_raw).shape))\n",
    "print(\"Train_y: {}\".format(np.array(train_y_raw).shape))\n",
    "print(\"Validation_y: {}\".format(np.array(val_y_raw).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(batch_size=20, lstm_size=1000, num_layers=1, learning_rate=0.001, grad_clip=1):\n",
    "    \n",
    "    # reset graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope('inputs_1'):\n",
    "        inputs_1 = tf.placeholder(tf.float32, [None, None, 4096], name=\"inputs_1\")\n",
    "    with tf.name_scope('inputs_2'):\n",
    "        inputs_2 = tf.placeholder(tf.float32, [None, None, 4096], name=\"inputs_2\")\n",
    "    with tf.name_scope('targets'):\n",
    "        target_ = tf.placeholder(tf.float32, [None, 2], name=\"targets\")\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    \n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "#     seq_length = tf.placeholder(tf.int32, (None, ), name='seq_length')\n",
    "    with tf.variable_scope(\"LSTM\"):\n",
    "#         with tf.name_scope(\"RNN_cells_1\"):\n",
    "            # Your basic LSTM cell\n",
    "        #         lstm = tf.contrib.rnn.LSTMBlockFusedCell(lstm_size, forget_bias=1.0, use_peephole=True)\n",
    "        #         lstm = tf.nn.relu(lstm)\n",
    "        lstm_1 = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "            # Add dropout to the cell\n",
    "        drop_1 = tf.contrib.rnn.DropoutWrapper(lstm_1, output_keep_prob=keep_prob)\n",
    "            # Stack up multiple LSTM layers, for deep learning\n",
    "        cell_1 = tf.contrib.rnn.MultiRNNCell([drop_1] * num_layers)\n",
    "\n",
    "#         with tf.name_scope(\"RNN_init_state_1\"):\n",
    "            # Getting an initial state of all zeros\n",
    "        initial_state_1 = cell_1.zero_state(batch_size, tf.float32)\n",
    "\n",
    "#         with tf.name_scope(\"RNN_forward_1\"):\n",
    "        outputs_1, final_state_1 = tf.nn.dynamic_rnn(cell_1, inputs_1, initial_state=initial_state_1)\n",
    "\n",
    "    with tf.variable_scope(\"LSTM\", reuse=True):\n",
    "#         with tf.name_scope(\"RNN_cells_2\"):\n",
    "            # Your basic LSTM cell\n",
    "    #         lstm = tf.contrib.rnn.LSTMBlockFusedCell(lstm_size, forget_bias=1.0, use_peephole=True)\n",
    "    #         lstm = tf.nn.relu(lstm)\n",
    "        lstm_2 = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "            # Add dropout to the cell\n",
    "        drop_2 = tf.contrib.rnn.DropoutWrapper(lstm_2, output_keep_prob=keep_prob)\n",
    "            # Stack up multiple LSTM layers, for deep learning\n",
    "        cell_2 = tf.contrib.rnn.MultiRNNCell([drop_2] * num_layers)\n",
    "\n",
    "#         with tf.name_scope(\"RNN_init_state_2\"):\n",
    "            # Getting an initial state of all zeros\n",
    "        initial_state_2 = cell_2.zero_state(batch_size, tf.float32)\n",
    "\n",
    "#         with tf.name_scope(\"RNN_forward_2\"):\n",
    "        outputs_2, final_state_2 = tf.nn.dynamic_rnn(cell_2, inputs_2, initial_state=initial_state_2)\n",
    "\n",
    "    with tf.name_scope('predictions'):\n",
    "        # only choose final one\n",
    "        final_output_concat = tf.concat([outputs_1[:, -1], outputs_2[:, -1]], 1)\n",
    "        logits = tf.contrib.layers.fully_connected(final_output_concat, 2)\n",
    "        predictions = tf.nn.softmax(logits, name='predictions')\n",
    "        tf.summary.histogram('predictions', predictions)\n",
    "        \n",
    "    with tf.name_scope('cost'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target_, logits=logits))\n",
    "        tf.summary.scalar('cost', cost)\n",
    "        \n",
    "    with tf.name_scope('train'):\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip, name='clip')\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "        optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "#         optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "        \n",
    "    with tf.name_scope('saver'):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    export_nodes = ['inputs_1', 'inputs_2', 'target_', 'initial_state_1', 'initial_state_2', 'outputs_1', 'outputs_2',\n",
    "                    'final_state_1', 'final_state_2', 'keep_prob', 'cost', 'logits', 'predictions', 'optimizer', \n",
    "                    'merged', 'saver', 'learning_rate', 'cell_1', 'cell_2', 'final_output_concat']\n",
    "    \n",
    "    Graph = collections.namedtuple('Graph', export_nodes)\n",
    "    local_dict = locals()\n",
    "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(data, target, batch_size):\n",
    "    n_batches = len(data)//batch_size\n",
    "    data = data[:batch_size * n_batches]\n",
    "    target = target[:batch_size * n_batches]\n",
    "    for ii in range(0, batch_size*n_batches, batch_size):\n",
    "        data_batch = data[ii:ii + batch_size]\n",
    "        target_batch = target[ii:ii + batch_size]\n",
    "        \n",
    "        yield data_batch, target_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x_raw\n",
    "val_x = val_x_raw\n",
    "train_y = train_y_raw\n",
    "val_y = val_y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, file_writer, save_string):\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        iteration = 1\n",
    "        mean_val_Acc = 0\n",
    "        mean_val_loss = 0\n",
    "        count_Acc_not_increase_epochs = 0\n",
    "        count_loss_not_decrease_epochs = 0\n",
    "        Last_val_Acc = 0\n",
    "        Last_val_loss = 0\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for train_batch, target_batch in get_batches(train_x, train_y, batch_size):\n",
    "                start = time.time()\n",
    "                \n",
    "#                 state_1 = sess.run(model.initial_state_1)\n",
    "#                 state_2 = sess.run(model.initial_state_2)\n",
    "#                 print(train_batch[:, :15, :].shape)\n",
    "#                 print(target_batch)\n",
    "    #             print('target: {}'.format(target_batch.shape))\n",
    "                feed = {model.inputs_1: train_batch[:, :15, :],\n",
    "                        model.inputs_2: train_batch[:, 15:, :],\n",
    "                        model.target_: target_batch,\n",
    "                        model.keep_prob: 1,\n",
    "#                         model.initial_state_1: state_1,\n",
    "#                         model.initial_state_2: state_2,\n",
    "                        model.learning_rate: lr,\n",
    "                        }\n",
    "#                 print(model.outputs_1.shape, model.outputs_1[:, -1], model.final_output_concat, \n",
    "#                       model.logits, model.predictions, model.cost)\n",
    "                loss, _, pred, summary = sess.run([model.cost, model.optimizer, model.predictions, model.merged], \\\n",
    "                                              feed_dict=feed)\n",
    "                print(pred)\n",
    "#                 print('pred: {}'.format(type(pred)))\n",
    "    #             print('pred: {}'.format(np.count_nonzero(pred)))\n",
    "    #             print('pred: {}'.format(np.sum(pred>0.1)))\n",
    "    #             print('pred: {}'.format(pred.size))\n",
    "    #             print('output: {}'.format(out[1, 39, :]))\n",
    "                \n",
    "                if iteration%5==0:\n",
    "                    end = time.time()\n",
    "#                     acc = calculate_accuracy(sess, pred, target_batch, sq_length)\n",
    "                    print(\"Epoch: {}/{},\".format(e+1, epochs),' ',\n",
    "                          \"Iteration: {},\".format(iteration),' ',\n",
    "                          \"Train loss: {:.3f},\".format(loss),' ',\n",
    "                          \"{:.1f}s /batch.\".format((end-start)/5),' '\n",
    "#                           \"ACCuracy: %{:.3f}\".format(acc)\n",
    "                         )\n",
    "                    \n",
    "                    file_writer.add_summary(summary, iteration)\n",
    "                \n",
    "#                 if iteration%25==0:\n",
    "#                     validation_loss = []\n",
    "#                     validation_Acc = []\n",
    "                    \n",
    "#                     if batch_size >= len(val_x):\n",
    "#                         val_batch_size = 30\n",
    "#                     else: \n",
    "#                         val_batch_size = batch_size\n",
    "                    \n",
    "#                     for val_batch, val_target_batch in get_batches(val_x, val_y, val_batch_size):\n",
    "\n",
    "#                         val_state_1 = sess.run(model.cell_1.zero_state(val_batch_size, tf.float32))\n",
    "#                         val_state_2 = sess.run(model.cell_2.zero_state(val_batch_size, tf.float32))\n",
    "\n",
    "#                         feed = {model.inputs_1: val_batch[:, :15, :],\n",
    "#                                 model.inputs_2: val_batch[:, 15:, :],\n",
    "#                                 model.target_: val_target_batch,\n",
    "#                                 model.keep_prob: 1,\n",
    "#                                 model.initial_state_1: val_state_1,\n",
    "#                                 model.initial_state_2: val_state_2,\n",
    "#                                }\n",
    "\n",
    "#                         val_loss, val_pred = sess.run([model.cost, model.predictions], feed_dict=feed)\n",
    "                        \n",
    "# #                         val_acc = calculate_accuracy(sess, val_pred, val_target_batch, val_sq_length)\n",
    "\n",
    "#                         validation_loss.append(val_loss)\n",
    "                        \n",
    "# #                         validation_Acc.append(val_acc)\n",
    "                        \n",
    "#                     Last_val_Acc = mean_val_Acc\n",
    "#                     Last_val_loss = mean_val_loss\n",
    "                        \n",
    "#                     mean_val_loss = sum(validation_loss)/len(validation_loss)  \n",
    "#                     mean_val_Acc = sum(validation_Acc)/len(validation_Acc)\n",
    "#                     print()\n",
    "#                     print(\"Validation loss: {:.3f},\".format(mean_val_loss), ' ',\n",
    "#                           \"Validation Accuracy: %{:.3f}\".format(mean_val_Acc))\n",
    "#                     print()\n",
    "                    \n",
    "                iteration += 1\n",
    "                \n",
    "            # Early stopping  \n",
    "#             if mean_val_Acc - Last_val_Acc <= -0.3:\n",
    "#                 count_Acc_not_increase_epochs += 1\n",
    "#             if Last_val_loss - mean_val_loss <= -0.01:\n",
    "#                 count_loss_not_decrease_epochs += 1\n",
    "            \n",
    "#             if count_Acc_not_increase_epochs >= 5:\n",
    "#                 break\n",
    "#             if count_loss_not_decrease_epochs >= 5:\n",
    "#                 break\n",
    "                \n",
    "        model.saver.save(sess, r\"{}\".format(save_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: checkpoints_identification: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49608701  0.50391304]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49706134  0.50293869]\n",
      " [ 0.50289142  0.49710855]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49075195  0.50924808]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50189316  0.4981069 ]\n",
      " [ 0.49599731  0.50400269]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50753748  0.49246252]\n",
      " [ 0.50232697  0.49767303]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50036168  0.49963829]\n",
      " [ 0.5011583   0.49884167]\n",
      " [ 0.51117843  0.48882157]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50293404  0.49706596]\n",
      " [ 0.50030583  0.49969411]\n",
      " [ 0.49320468  0.50679529]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5043686   0.49563143]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49439526  0.50560468]\n",
      " [ 0.50085318  0.49914679]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.51035708  0.48964292]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50825745  0.49174255]\n",
      " [ 0.4976927   0.50230736]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50054914  0.49945086]\n",
      " [ 0.50669801  0.49330193]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50179738  0.49820259]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50194657  0.4980534 ]\n",
      " [ 0.50555938  0.49444067]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50499845  0.49500155]\n",
      " [ 0.50263739  0.49736261]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50479186  0.49520817]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50462055  0.49537945]\n",
      " [ 0.50139064  0.49860936]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50334495  0.49665508]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50034714  0.49965292]\n",
      " [ 0.50037301  0.49962699]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50214195  0.49785799]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49856377  0.50143623]\n",
      " [ 0.49668607  0.50331396]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49937034  0.50062966]\n",
      " [ 0.50347477  0.49652526]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50470763  0.49529243]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50620168  0.49379829]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49451429  0.50548571]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50881052  0.49118948]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.50857836  0.4914217 ]\n",
      " [ 0.50141698  0.49858305]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]]\n",
      "[[ 0.97421443  0.02578559]\n",
      " [ 0.95940298  0.04059703]\n",
      " [ 0.94309855  0.0569014 ]\n",
      " [ 0.93554485  0.06445512]\n",
      " [ 0.95050955  0.04949043]\n",
      " [ 0.93274504  0.06725493]\n",
      " [ 0.95839763  0.04160239]\n",
      " [ 0.94194418  0.05805582]\n",
      " [ 0.94747978  0.05252023]\n",
      " [ 0.94375449  0.05624551]\n",
      " [ 0.93077719  0.06922281]\n",
      " [ 0.94477522  0.05522485]\n",
      " [ 0.95466262  0.04533733]\n",
      " [ 0.95570248  0.04429753]\n",
      " [ 0.94356841  0.05643157]\n",
      " [ 0.94337875  0.05662121]\n",
      " [ 0.95588797  0.04411207]\n",
      " [ 0.96746576  0.03253429]\n",
      " [ 0.96621299  0.03378697]\n",
      " [ 0.95255393  0.04744603]\n",
      " [ 0.94726354  0.05273644]\n",
      " [ 0.95366085  0.04633918]\n",
      " [ 0.94079775  0.05920227]\n",
      " [ 0.94459623  0.05540376]\n",
      " [ 0.96267349  0.03732643]\n",
      " [ 0.95542985  0.04457021]\n",
      " [ 0.95917839  0.04082156]\n",
      " [ 0.93576759  0.06423247]\n",
      " [ 0.95401704  0.04598299]\n",
      " [ 0.92390823  0.07609181]\n",
      " [ 0.95204204  0.04795802]\n",
      " [ 0.94850463  0.05149537]\n",
      " [ 0.95537281  0.04462723]\n",
      " [ 0.96328694  0.03671307]\n",
      " [ 0.94491369  0.05508634]\n",
      " [ 0.94392419  0.05607578]\n",
      " [ 0.9633075   0.03669253]\n",
      " [ 0.95761043  0.0423896 ]\n",
      " [ 0.93945122  0.06054881]\n",
      " [ 0.96576214  0.03423788]\n",
      " [ 0.95312226  0.04687776]\n",
      " [ 0.96242279  0.03757719]\n",
      " [ 0.95568043  0.04431962]\n",
      " [ 0.96813679  0.03186318]\n",
      " [ 0.95119619  0.04880377]\n",
      " [ 0.95938325  0.04061678]\n",
      " [ 0.93870777  0.06129226]\n",
      " [ 0.94751137  0.05248868]\n",
      " [ 0.94149381  0.05850624]\n",
      " [ 0.96681714  0.03318284]\n",
      " [ 0.95129848  0.04870154]\n",
      " [ 0.96571958  0.03428045]\n",
      " [ 0.93624228  0.06375773]\n",
      " [ 0.94843853  0.05156144]\n",
      " [ 0.95267779  0.04732217]\n",
      " [ 0.96210158  0.03789839]\n",
      " [ 0.95196956  0.04803051]\n",
      " [ 0.94791114  0.05208888]\n",
      " [ 0.96799266  0.03200732]\n",
      " [ 0.94057757  0.0594224 ]\n",
      " [ 0.94316155  0.05683843]\n",
      " [ 0.93758672  0.0624133 ]\n",
      " [ 0.94278502  0.05721497]\n",
      " [ 0.95090133  0.04909866]\n",
      " [ 0.94872206  0.05127792]\n",
      " [ 0.9553777   0.04462229]\n",
      " [ 0.93434072  0.06565934]\n",
      " [ 0.96980727  0.03019273]\n",
      " [ 0.95002598  0.04997396]\n",
      " [ 0.94721246  0.05278761]\n",
      " [ 0.96639442  0.03360553]\n",
      " [ 0.95200759  0.04799239]\n",
      " [ 0.96071613  0.03928393]\n",
      " [ 0.93786752  0.06213247]\n",
      " [ 0.94862729  0.05137273]\n",
      " [ 0.96020126  0.03979875]\n",
      " [ 0.92027992  0.07972009]\n",
      " [ 0.95744443  0.04255561]\n",
      " [ 0.9401952   0.05980482]\n",
      " [ 0.94369894  0.05630103]\n",
      " [ 0.96309304  0.03690698]\n",
      " [ 0.94681352  0.0531864 ]\n",
      " [ 0.96986806  0.030132  ]\n",
      " [ 0.94483405  0.05516594]\n",
      " [ 0.95466292  0.04533705]\n",
      " [ 0.94012737  0.05987266]\n",
      " [ 0.94235802  0.05764199]\n",
      " [ 0.93886304  0.06113691]\n",
      " [ 0.93296993  0.06703004]\n",
      " [ 0.931265    0.06873495]\n",
      " [ 0.95266759  0.04733232]\n",
      " [ 0.95816749  0.04183247]\n",
      " [ 0.96084398  0.039156  ]\n",
      " [ 0.95042795  0.04957213]\n",
      " [ 0.95996565  0.04003433]\n",
      " [ 0.94383383  0.05616621]\n",
      " [ 0.95148808  0.04851196]\n",
      " [ 0.95719796  0.04280209]\n",
      " [ 0.94392151  0.05607851]\n",
      " [ 0.96181047  0.03818948]]\n",
      "[[ 0.4457919   0.55420804]\n",
      " [ 0.43559718  0.56440288]\n",
      " [ 0.45248821  0.54751176]\n",
      " [ 0.40292993  0.5970701 ]\n",
      " [ 0.4368532   0.56314683]\n",
      " [ 0.40169406  0.59830594]\n",
      " [ 0.50237751  0.49762252]\n",
      " [ 0.41091561  0.58908439]\n",
      " [ 0.46630934  0.53369063]\n",
      " [ 0.40345213  0.59654784]\n",
      " [ 0.40132964  0.59867042]\n",
      " [ 0.39513102  0.60486901]\n",
      " [ 0.40569508  0.59430492]\n",
      " [ 0.42654151  0.57345849]\n",
      " [ 0.40703678  0.59296322]\n",
      " [ 0.43553877  0.56446117]\n",
      " [ 0.39393121  0.60606879]\n",
      " [ 0.45472586  0.54527414]\n",
      " [ 0.40833607  0.5916639 ]\n",
      " [ 0.43878436  0.56121564]\n",
      " [ 0.47712025  0.52287978]\n",
      " [ 0.42192087  0.5780791 ]\n",
      " [ 0.39819434  0.60180563]\n",
      " [ 0.44112754  0.55887246]\n",
      " [ 0.39430127  0.6056987 ]\n",
      " [ 0.41996363  0.5800364 ]\n",
      " [ 0.35558924  0.64441073]\n",
      " [ 0.42685774  0.57314223]\n",
      " [ 0.41776323  0.58223677]\n",
      " [ 0.39359561  0.60640442]\n",
      " [ 0.45421895  0.54578108]\n",
      " [ 0.39769337  0.6023066 ]\n",
      " [ 0.39441949  0.60558051]\n",
      " [ 0.46086374  0.53913623]\n",
      " [ 0.40448558  0.59551436]\n",
      " [ 0.44689459  0.55310541]\n",
      " [ 0.41452491  0.58547515]\n",
      " [ 0.45912385  0.54087615]\n",
      " [ 0.42290789  0.57709211]\n",
      " [ 0.39139473  0.60860521]\n",
      " [ 0.394122    0.60587806]\n",
      " [ 0.41428962  0.58571035]\n",
      " [ 0.38174933  0.61825067]\n",
      " [ 0.44922712  0.55077291]\n",
      " [ 0.39368001  0.60631996]\n",
      " [ 0.38461038  0.61538959]\n",
      " [ 0.47541159  0.52458841]\n",
      " [ 0.43739751  0.56260252]\n",
      " [ 0.45088434  0.54911566]\n",
      " [ 0.41000801  0.58999205]\n",
      " [ 0.45143887  0.54856116]\n",
      " [ 0.46707991  0.53292012]\n",
      " [ 0.39800608  0.60199392]\n",
      " [ 0.47664717  0.52335286]\n",
      " [ 0.36588275  0.63411725]\n",
      " [ 0.42456856  0.57543147]\n",
      " [ 0.46020305  0.53979689]\n",
      " [ 0.42098278  0.57901728]\n",
      " [ 0.42892408  0.57107598]\n",
      " [ 0.42872325  0.57127678]\n",
      " [ 0.4271577   0.57284236]\n",
      " [ 0.4194648   0.58053517]\n",
      " [ 0.40984082  0.59015924]\n",
      " [ 0.41434765  0.58565229]\n",
      " [ 0.43690318  0.56309676]\n",
      " [ 0.42680505  0.57319492]\n",
      " [ 0.38149434  0.61850566]\n",
      " [ 0.4424969   0.55750304]\n",
      " [ 0.37749279  0.62250715]\n",
      " [ 0.45388633  0.54611367]\n",
      " [ 0.44462946  0.55537051]\n",
      " [ 0.44944507  0.55055493]\n",
      " [ 0.43409738  0.56590259]\n",
      " [ 0.40791437  0.5920856 ]\n",
      " [ 0.40288419  0.59711581]\n",
      " [ 0.45202836  0.54797167]\n",
      " [ 0.46571812  0.53428185]\n",
      " [ 0.48398733  0.51601267]\n",
      " [ 0.44289267  0.55710733]\n",
      " [ 0.39268067  0.60731936]\n",
      " [ 0.4371554   0.56284451]\n",
      " [ 0.42228004  0.57771993]\n",
      " [ 0.42306849  0.57693154]\n",
      " [ 0.40727937  0.59272063]\n",
      " [ 0.4265984   0.57340157]\n",
      " [ 0.39715675  0.60284328]\n",
      " [ 0.43890777  0.5610922 ]\n",
      " [ 0.48506239  0.51493758]\n",
      " [ 0.4669207   0.53307927]\n",
      " [ 0.41549295  0.58450699]\n",
      " [ 0.42661455  0.57338542]\n",
      " [ 0.44421762  0.55578238]\n",
      " [ 0.42488527  0.57511467]\n",
      " [ 0.44374099  0.55625898]\n",
      " [ 0.41242969  0.58757031]\n",
      " [ 0.47113776  0.52886224]\n",
      " [ 0.41283885  0.58716112]\n",
      " [ 0.44547305  0.55452693]\n",
      " [ 0.44536766  0.55463231]\n",
      " [ 0.43245327  0.56754667]]\n",
      "[[ 0.14457653  0.85542351]\n",
      " [ 0.18612662  0.81387335]\n",
      " [ 0.17862132  0.82137877]\n",
      " [ 0.21816774  0.78183222]\n",
      " [ 0.20228495  0.79771507]\n",
      " [ 0.16022743  0.83977252]\n",
      " [ 0.16088936  0.83911061]\n",
      " [ 0.17809615  0.82190388]\n",
      " [ 0.13735716  0.86264282]\n",
      " [ 0.21324156  0.78675842]\n",
      " [ 0.19134569  0.80865431]\n",
      " [ 0.15736952  0.84263051]\n",
      " [ 0.14664803  0.85335201]\n",
      " [ 0.2135859   0.78641409]\n",
      " [ 0.14462718  0.85537285]\n",
      " [ 0.13363065  0.86636931]\n",
      " [ 0.17532454  0.8246755 ]\n",
      " [ 0.21128167  0.78871834]\n",
      " [ 0.16389318  0.83610684]\n",
      " [ 0.18769588  0.81230414]\n",
      " [ 0.1502365   0.84976351]\n",
      " [ 0.18537179  0.81462824]\n",
      " [ 0.16434935  0.83565062]\n",
      " [ 0.19025177  0.80974823]\n",
      " [ 0.18702975  0.81297028]\n",
      " [ 0.15554574  0.84445429]\n",
      " [ 0.170449    0.82955098]\n",
      " [ 0.1601046   0.83989537]\n",
      " [ 0.19199041  0.80800962]\n",
      " [ 0.154357    0.84564304]\n",
      " [ 0.17704208  0.82295793]\n",
      " [ 0.14728078  0.85271919]\n",
      " [ 0.16236828  0.83763164]\n",
      " [ 0.20013741  0.79986262]\n",
      " [ 0.20600034  0.79399967]\n",
      " [ 0.17375872  0.82624131]\n",
      " [ 0.15600966  0.84399033]\n",
      " [ 0.16891673  0.8310833 ]\n",
      " [ 0.19259495  0.80740505]\n",
      " [ 0.2040423   0.79595774]\n",
      " [ 0.18059511  0.81940484]\n",
      " [ 0.17825653  0.82174349]\n",
      " [ 0.16031231  0.83968771]\n",
      " [ 0.18671905  0.81328094]\n",
      " [ 0.19809268  0.8019073 ]\n",
      " [ 0.16683365  0.83316636]\n",
      " [ 0.19299845  0.80700153]\n",
      " [ 0.15128507  0.84871489]\n",
      " [ 0.17649044  0.82350957]\n",
      " [ 0.20001042  0.79998952]\n",
      " [ 0.24490754  0.75509244]\n",
      " [ 0.19546124  0.80453879]\n",
      " [ 0.17101265  0.82898742]\n",
      " [ 0.1714091   0.82859093]\n",
      " [ 0.16448516  0.83551484]\n",
      " [ 0.16676843  0.83323157]\n",
      " [ 0.18888126  0.81111878]\n",
      " [ 0.13995381  0.86004621]\n",
      " [ 0.19585146  0.8041485 ]\n",
      " [ 0.14274462  0.85725534]\n",
      " [ 0.15580511  0.84419495]\n",
      " [ 0.19713098  0.80286896]\n",
      " [ 0.20973021  0.79026979]\n",
      " [ 0.17341712  0.82658291]\n",
      " [ 0.17181118  0.82818884]\n",
      " [ 0.19386628  0.80613369]\n",
      " [ 0.20656319  0.79343677]\n",
      " [ 0.16492304  0.83507699]\n",
      " [ 0.17996478  0.82003528]\n",
      " [ 0.16063672  0.83936322]\n",
      " [ 0.20478436  0.79521561]\n",
      " [ 0.2159429   0.78405708]\n",
      " [ 0.17300293  0.8269971 ]\n",
      " [ 0.17832243  0.82167757]\n",
      " [ 0.19663836  0.80336171]\n",
      " [ 0.15663981  0.84336019]\n",
      " [ 0.16620737  0.83379269]\n",
      " [ 0.19406411  0.80593592]\n",
      " [ 0.15468663  0.84531343]\n",
      " [ 0.14148609  0.85851389]\n",
      " [ 0.18420932  0.81579071]\n",
      " [ 0.18780929  0.81219071]\n",
      " [ 0.1408129   0.85918713]\n",
      " [ 0.16728456  0.83271545]\n",
      " [ 0.15321401  0.84678602]\n",
      " [ 0.19395533  0.80604464]\n",
      " [ 0.14831334  0.85168672]\n",
      " [ 0.19067284  0.80932719]\n",
      " [ 0.17562659  0.82437342]\n",
      " [ 0.15054157  0.8494584 ]\n",
      " [ 0.15968627  0.84031367]\n",
      " [ 0.16259108  0.8374089 ]\n",
      " [ 0.17353214  0.82646781]\n",
      " [ 0.18428485  0.81571513]\n",
      " [ 0.17288122  0.82711875]\n",
      " [ 0.15261939  0.84738064]\n",
      " [ 0.14516813  0.85483187]\n",
      " [ 0.15463996  0.8453601 ]\n",
      " [ 0.14217286  0.85782719]\n",
      " [ 0.19493367  0.80506635]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.45391771  0.54608238]\n",
      " [ 0.41446188  0.58553815]\n",
      " [ 0.44353905  0.55646098]\n",
      " [ 0.41445121  0.58554876]\n",
      " [ 0.40956676  0.5904333 ]\n",
      " [ 0.39607745  0.60392261]\n",
      " [ 0.37358496  0.62641501]\n",
      " [ 0.37828946  0.62171054]\n",
      " [ 0.42571038  0.57428962]\n",
      " [ 0.42694327  0.57305676]\n",
      " [ 0.40742856  0.59257144]\n",
      " [ 0.40751705  0.59248292]\n",
      " [ 0.43959045  0.56040955]\n",
      " [ 0.43684936  0.56315064]\n",
      " [ 0.37235302  0.62764704]\n",
      " [ 0.43269423  0.56730574]\n",
      " [ 0.36047634  0.63952368]\n",
      " [ 0.44043919  0.55956084]\n",
      " [ 0.3939229   0.60607713]\n",
      " [ 0.37674376  0.62325621]\n",
      " [ 0.39399403  0.60600597]\n",
      " [ 0.43028864  0.56971139]\n",
      " [ 0.39946243  0.6005376 ]\n",
      " [ 0.42782632  0.57217371]\n",
      " [ 0.38674593  0.61325407]\n",
      " [ 0.3565042   0.6434958 ]\n",
      " [ 0.41637823  0.58362174]\n",
      " [ 0.39430049  0.60569948]\n",
      " [ 0.44334909  0.55665082]\n",
      " [ 0.46437722  0.53562278]\n",
      " [ 0.38222298  0.61777693]\n",
      " [ 0.39069813  0.60930181]\n",
      " [ 0.43745369  0.56254631]\n",
      " [ 0.41488105  0.58511901]\n",
      " [ 0.36672303  0.63327694]\n",
      " [ 0.39538577  0.60461414]\n",
      " [ 0.42394388  0.57605612]\n",
      " [ 0.39909947  0.60090059]\n",
      " [ 0.45689699  0.54310298]\n",
      " [ 0.43216705  0.56783295]\n",
      " [ 0.36615992  0.63384008]\n",
      " [ 0.39847505  0.60152495]\n",
      " [ 0.38476235  0.61523765]\n",
      " [ 0.39731467  0.60268533]\n",
      " [ 0.42678508  0.57321489]\n",
      " [ 0.36945882  0.63054121]\n",
      " [ 0.38065067  0.61934936]\n",
      " [ 0.41957873  0.58042127]\n",
      " [ 0.4512035   0.54879647]\n",
      " [ 0.36010316  0.63989687]\n",
      " [ 0.39257476  0.60742521]\n",
      " [ 0.44422972  0.55577022]\n",
      " [ 0.47430131  0.52569872]\n",
      " [ 0.41482958  0.58517045]\n",
      " [ 0.34375268  0.65624732]\n",
      " [ 0.39560166  0.60439837]\n",
      " [ 0.37550586  0.62449408]\n",
      " [ 0.43620229  0.56379771]\n",
      " [ 0.43234205  0.56765789]\n",
      " [ 0.43997702  0.56002295]\n",
      " [ 0.34843805  0.65156198]\n",
      " [ 0.42824617  0.57175386]\n",
      " [ 0.45176291  0.54823709]\n",
      " [ 0.43920702  0.56079298]\n",
      " [ 0.42524502  0.57475501]\n",
      " [ 0.38726979  0.61273021]\n",
      " [ 0.40410224  0.59589779]\n",
      " [ 0.39723602  0.60276401]\n",
      " [ 0.37385631  0.62614375]\n",
      " [ 0.448082    0.55191797]\n",
      " [ 0.38720402  0.61279595]\n",
      " [ 0.40304089  0.59695911]\n",
      " [ 0.31924114  0.68075883]\n",
      " [ 0.39252669  0.60747331]\n",
      " [ 0.36215499  0.63784498]\n",
      " [ 0.34949467  0.6505053 ]\n",
      " [ 0.36710751  0.63289249]\n",
      " [ 0.40855804  0.59144193]\n",
      " [ 0.44070429  0.55929565]\n",
      " [ 0.37761959  0.62238038]\n",
      " [ 0.46027714  0.5397228 ]\n",
      " [ 0.36282745  0.63717258]\n",
      " [ 0.36023766  0.63976228]\n",
      " [ 0.44657254  0.5534274 ]\n",
      " [ 0.45075729  0.54924268]\n",
      " [ 0.49430439  0.50569564]\n",
      " [ 0.36855155  0.63144845]\n",
      " [ 0.40162981  0.59837019]\n",
      " [ 0.44176435  0.55823565]\n",
      " [ 0.39252481  0.60747522]\n",
      " [ 0.37651768  0.62348235]\n",
      " [ 0.45887387  0.54112613]\n",
      " [ 0.41091067  0.58908933]\n",
      " [ 0.47778955  0.52221036]\n",
      " [ 0.42677408  0.57322592]\n",
      " [ 0.42010099  0.57989901]\n",
      " [ 0.38877198  0.61122799]\n",
      " [ 0.48284733  0.51715273]\n",
      " [ 0.45441034  0.54558957]\n",
      " [ 0.40188536  0.59811461]]\n",
      "Epoch: 1/1000,   Iteration: 5,   Train loss: 0.736,   9.9s /batch.  \n",
      "[[ 0.77301711  0.22698288]\n",
      " [ 0.73144847  0.26855159]\n",
      " [ 0.70573658  0.29426342]\n",
      " [ 0.80450153  0.19549847]\n",
      " [ 0.82267171  0.17732833]\n",
      " [ 0.77104169  0.22895834]\n",
      " [ 0.79371691  0.20628317]\n",
      " [ 0.82796681  0.17203318]\n",
      " [ 0.72621548  0.27378446]\n",
      " [ 0.77952504  0.22047493]\n",
      " [ 0.73057777  0.26942217]\n",
      " [ 0.76650304  0.23349695]\n",
      " [ 0.77778542  0.22221459]\n",
      " [ 0.79220879  0.20779118]\n",
      " [ 0.82076007  0.1792399 ]\n",
      " [ 0.79818618  0.20181386]\n",
      " [ 0.7577129   0.24228704]\n",
      " [ 0.77672857  0.22327144]\n",
      " [ 0.75455904  0.24544097]\n",
      " [ 0.73763388  0.26236612]\n",
      " [ 0.76130927  0.23869073]\n",
      " [ 0.7860657   0.2139343 ]\n",
      " [ 0.7211442   0.27885583]\n",
      " [ 0.79493916  0.20506081]\n",
      " [ 0.81551737  0.18448262]\n",
      " [ 0.77974498  0.22025505]\n",
      " [ 0.73855746  0.26144254]\n",
      " [ 0.74998301  0.25001699]\n",
      " [ 0.78864145  0.21135852]\n",
      " [ 0.76945639  0.23054366]\n",
      " [ 0.79618698  0.20381296]\n",
      " [ 0.74053311  0.25946695]\n",
      " [ 0.75088692  0.24911316]\n",
      " [ 0.76620591  0.233794  ]\n",
      " [ 0.80063885  0.19936116]\n",
      " [ 0.74618345  0.25381649]\n",
      " [ 0.76854557  0.23145446]\n",
      " [ 0.78175151  0.21824847]\n",
      " [ 0.81320381  0.18679617]\n",
      " [ 0.78159058  0.21840939]\n",
      " [ 0.74313968  0.25686035]\n",
      " [ 0.70722419  0.29277587]\n",
      " [ 0.76402366  0.23597631]\n",
      " [ 0.73460621  0.26539376]\n",
      " [ 0.77945364  0.22054636]\n",
      " [ 0.74843478  0.25156525]\n",
      " [ 0.73364997  0.26635003]\n",
      " [ 0.79850608  0.2014939 ]\n",
      " [ 0.74284548  0.25715455]\n",
      " [ 0.79738635  0.20261364]\n",
      " [ 0.75167102  0.24832895]\n",
      " [ 0.75706398  0.24293599]\n",
      " [ 0.79655892  0.20344113]\n",
      " [ 0.76905578  0.23094425]\n",
      " [ 0.77334887  0.22665115]\n",
      " [ 0.77192283  0.22807719]\n",
      " [ 0.74960303  0.25039703]\n",
      " [ 0.82639384  0.17360623]\n",
      " [ 0.78392178  0.21607825]\n",
      " [ 0.75825721  0.24174277]\n",
      " [ 0.6829412   0.31705877]\n",
      " [ 0.75407958  0.24592045]\n",
      " [ 0.79141986  0.20858014]\n",
      " [ 0.76821774  0.2317823 ]\n",
      " [ 0.74967378  0.25032619]\n",
      " [ 0.75136817  0.24863181]\n",
      " [ 0.73991156  0.26008841]\n",
      " [ 0.7100814   0.28991851]\n",
      " [ 0.78172457  0.21827541]\n",
      " [ 0.77345383  0.22654614]\n",
      " [ 0.76306343  0.23693655]\n",
      " [ 0.74810344  0.25189653]\n",
      " [ 0.76732087  0.23267913]\n",
      " [ 0.77484483  0.22515517]\n",
      " [ 0.79024208  0.20975791]\n",
      " [ 0.67362744  0.32637259]\n",
      " [ 0.76966655  0.23033346]\n",
      " [ 0.79880446  0.20119557]\n",
      " [ 0.75517231  0.24482772]\n",
      " [ 0.78864592  0.21135411]\n",
      " [ 0.75646943  0.24353059]\n",
      " [ 0.74343389  0.25656611]\n",
      " [ 0.81829202  0.18170798]\n",
      " [ 0.75995392  0.24004607]\n",
      " [ 0.76372993  0.23627008]\n",
      " [ 0.77555621  0.22444382]\n",
      " [ 0.7139647   0.2860353 ]\n",
      " [ 0.78122193  0.21877812]\n",
      " [ 0.71723777  0.28276217]\n",
      " [ 0.82786471  0.17213532]\n",
      " [ 0.77259636  0.22740363]\n",
      " [ 0.82255101  0.17744896]\n",
      " [ 0.76230389  0.23769605]\n",
      " [ 0.75476599  0.24523404]\n",
      " [ 0.77453774  0.22546221]\n",
      " [ 0.71542603  0.28457388]\n",
      " [ 0.75596106  0.24403895]\n",
      " [ 0.75487196  0.24512807]\n",
      " [ 0.79058951  0.20941047]\n",
      " [ 0.81110168  0.18889831]]\n",
      "[[ 0.7581225   0.24187751]\n",
      " [ 0.8023141   0.19768584]\n",
      " [ 0.78295857  0.21704142]\n",
      " [ 0.74405062  0.25594947]\n",
      " [ 0.77994162  0.22005841]\n",
      " [ 0.77309483  0.22690514]\n",
      " [ 0.72375685  0.27624312]\n",
      " [ 0.78842199  0.21157798]\n",
      " [ 0.7697559   0.23024414]\n",
      " [ 0.79834831  0.20165171]\n",
      " [ 0.7976163   0.20238368]\n",
      " [ 0.75487792  0.24512213]\n",
      " [ 0.73535812  0.26464188]\n",
      " [ 0.81012148  0.18987852]\n",
      " [ 0.81161338  0.18838659]\n",
      " [ 0.81327093  0.18672907]\n",
      " [ 0.74931586  0.2506842 ]\n",
      " [ 0.81350183  0.18649815]\n",
      " [ 0.7483083   0.2516917 ]\n",
      " [ 0.74313748  0.25686255]\n",
      " [ 0.77977127  0.22022873]\n",
      " [ 0.72469848  0.27530155]\n",
      " [ 0.77611327  0.22388671]\n",
      " [ 0.79529315  0.20470685]\n",
      " [ 0.80244476  0.19755529]\n",
      " [ 0.81533146  0.18466853]\n",
      " [ 0.8162871   0.18371285]\n",
      " [ 0.78600943  0.21399052]\n",
      " [ 0.78134561  0.21865433]\n",
      " [ 0.76057512  0.2394249 ]\n",
      " [ 0.78682989  0.21317017]\n",
      " [ 0.81144923  0.18855077]\n",
      " [ 0.81887954  0.18112041]\n",
      " [ 0.82491392  0.17508611]\n",
      " [ 0.83044302  0.16955701]\n",
      " [ 0.75269163  0.24730834]\n",
      " [ 0.78939068  0.21060929]\n",
      " [ 0.79276097  0.20723902]\n",
      " [ 0.77253056  0.22746947]\n",
      " [ 0.84446084  0.15553916]\n",
      " [ 0.7725566   0.22744337]\n",
      " [ 0.80416936  0.19583069]\n",
      " [ 0.74741673  0.25258321]\n",
      " [ 0.77376002  0.22623996]\n",
      " [ 0.77964294  0.22035708]\n",
      " [ 0.79598886  0.20401119]\n",
      " [ 0.76895356  0.23104648]\n",
      " [ 0.80189931  0.19810064]\n",
      " [ 0.68898004  0.31101999]\n",
      " [ 0.73188406  0.26811591]\n",
      " [ 0.76534331  0.23465668]\n",
      " [ 0.7747432   0.22525674]\n",
      " [ 0.77364129  0.22635868]\n",
      " [ 0.77338439  0.22661567]\n",
      " [ 0.78328258  0.21671742]\n",
      " [ 0.8167007   0.18329935]\n",
      " [ 0.76256883  0.23743111]\n",
      " [ 0.84900659  0.15099345]\n",
      " [ 0.78169078  0.21830925]\n",
      " [ 0.77938408  0.22061592]\n",
      " [ 0.68979782  0.31020218]\n",
      " [ 0.79352647  0.20647353]\n",
      " [ 0.77704847  0.22295155]\n",
      " [ 0.7616809   0.23831916]\n",
      " [ 0.81742769  0.18257229]\n",
      " [ 0.75975496  0.24024501]\n",
      " [ 0.8112092   0.18879084]\n",
      " [ 0.74156398  0.25843605]\n",
      " [ 0.80043012  0.19956981]\n",
      " [ 0.78346568  0.2165343 ]\n",
      " [ 0.73705775  0.26294228]\n",
      " [ 0.74841219  0.25158775]\n",
      " [ 0.725564    0.27443606]\n",
      " [ 0.77372921  0.22627078]\n",
      " [ 0.77961379  0.22038618]\n",
      " [ 0.81937122  0.18062879]\n",
      " [ 0.71059293  0.28940707]\n",
      " [ 0.7806142   0.21938585]\n",
      " [ 0.76718903  0.23281097]\n",
      " [ 0.74896514  0.25103489]\n",
      " [ 0.74308825  0.25691178]\n",
      " [ 0.7948305   0.20516947]\n",
      " [ 0.80816269  0.19183739]\n",
      " [ 0.75457889  0.2454211 ]\n",
      " [ 0.69722486  0.30277517]\n",
      " [ 0.82356495  0.17643501]\n",
      " [ 0.76582825  0.23417173]\n",
      " [ 0.80499721  0.19500278]\n",
      " [ 0.78745508  0.21254484]\n",
      " [ 0.72173935  0.27826068]\n",
      " [ 0.77937371  0.22062625]\n",
      " [ 0.75519997  0.2448    ]\n",
      " [ 0.79497862  0.20502141]\n",
      " [ 0.72129267  0.27870727]\n",
      " [ 0.80929494  0.19070508]\n",
      " [ 0.86243796  0.13756208]\n",
      " [ 0.81578583  0.1842142 ]\n",
      " [ 0.79938179  0.20061818]\n",
      " [ 0.76092064  0.23907945]\n",
      " [ 0.84086156  0.15913847]]\n",
      "[[ 0.57561284  0.42438716]\n",
      " [ 0.67278868  0.32721129]\n",
      " [ 0.66613305  0.33386701]\n",
      " [ 0.66043979  0.33956024]\n",
      " [ 0.68016374  0.31983617]\n",
      " [ 0.65528262  0.34471741]\n",
      " [ 0.6742242   0.32577577]\n",
      " [ 0.60381925  0.39618072]\n",
      " [ 0.66141576  0.33858418]\n",
      " [ 0.77271992  0.22728011]\n",
      " [ 0.67320091  0.32679906]\n",
      " [ 0.63116699  0.36883304]\n",
      " [ 0.62067693  0.37932307]\n",
      " [ 0.65792066  0.3420794 ]\n",
      " [ 0.72361445  0.27638555]\n",
      " [ 0.6906271   0.30937296]\n",
      " [ 0.69564271  0.30435732]\n",
      " [ 0.72405064  0.27594939]\n",
      " [ 0.67680448  0.32319549]\n",
      " [ 0.63757914  0.36242086]\n",
      " [ 0.67491579  0.32508424]\n",
      " [ 0.59572309  0.40427691]\n",
      " [ 0.6808809   0.31911907]\n",
      " [ 0.68373698  0.31626305]\n",
      " [ 0.69810802  0.30189198]\n",
      " [ 0.62842727  0.37157273]\n",
      " [ 0.60119873  0.39880127]\n",
      " [ 0.60052204  0.39947796]\n",
      " [ 0.59406477  0.40593526]\n",
      " [ 0.70081508  0.29918495]\n",
      " [ 0.60559386  0.39440614]\n",
      " [ 0.65505815  0.34494182]\n",
      " [ 0.69333172  0.30666825]\n",
      " [ 0.60474879  0.39525121]\n",
      " [ 0.71897304  0.2810269 ]\n",
      " [ 0.63040131  0.36959863]\n",
      " [ 0.74758136  0.25241864]\n",
      " [ 0.64507788  0.35492212]\n",
      " [ 0.68160403  0.31839591]\n",
      " [ 0.65260744  0.34739259]\n",
      " [ 0.60394883  0.39605111]\n",
      " [ 0.67151999  0.32847995]\n",
      " [ 0.65615809  0.34384188]\n",
      " [ 0.63775408  0.36224592]\n",
      " [ 0.69472241  0.30527756]\n",
      " [ 0.72475636  0.27524358]\n",
      " [ 0.63841057  0.36158937]\n",
      " [ 0.75015622  0.24984375]\n",
      " [ 0.72598523  0.2740148 ]\n",
      " [ 0.74686044  0.25313953]\n",
      " [ 0.63123983  0.36876014]\n",
      " [ 0.7292425   0.27075753]\n",
      " [ 0.63950247  0.36049762]\n",
      " [ 0.59569728  0.40430272]\n",
      " [ 0.65303183  0.34696811]\n",
      " [ 0.61337459  0.38662535]\n",
      " [ 0.64682603  0.35317394]\n",
      " [ 0.63663244  0.3633675 ]\n",
      " [ 0.68166262  0.31833735]\n",
      " [ 0.74918592  0.25081408]\n",
      " [ 0.65060675  0.34939325]\n",
      " [ 0.70313716  0.29686281]\n",
      " [ 0.61516595  0.38483408]\n",
      " [ 0.64993155  0.35006845]\n",
      " [ 0.71864206  0.28135794]\n",
      " [ 0.65494317  0.34505686]\n",
      " [ 0.67204189  0.3279582 ]\n",
      " [ 0.65351099  0.34648898]\n",
      " [ 0.6414097   0.3585903 ]\n",
      " [ 0.695288    0.30471197]\n",
      " [ 0.61345005  0.38654998]\n",
      " [ 0.61121291  0.38878709]\n",
      " [ 0.7267136   0.27328631]\n",
      " [ 0.64682138  0.35317859]\n",
      " [ 0.69297808  0.30702195]\n",
      " [ 0.66999787  0.3300021 ]\n",
      " [ 0.68820548  0.31179455]\n",
      " [ 0.75483769  0.24516228]\n",
      " [ 0.71227336  0.28772661]\n",
      " [ 0.56407201  0.43592805]\n",
      " [ 0.69380653  0.3061935 ]\n",
      " [ 0.59031874  0.40968129]\n",
      " [ 0.65565556  0.3443445 ]\n",
      " [ 0.67249614  0.32750386]\n",
      " [ 0.67716736  0.32283273]\n",
      " [ 0.70362198  0.29637808]\n",
      " [ 0.67049921  0.32950082]\n",
      " [ 0.68102342  0.31897655]\n",
      " [ 0.61351746  0.38648257]\n",
      " [ 0.66510546  0.3348946 ]\n",
      " [ 0.67652601  0.32347399]\n",
      " [ 0.71020031  0.2897996 ]\n",
      " [ 0.62478453  0.37521544]\n",
      " [ 0.65168124  0.3483187 ]\n",
      " [ 0.69655293  0.30344701]\n",
      " [ 0.64973879  0.35026121]\n",
      " [ 0.6633727   0.3366273 ]\n",
      " [ 0.58955169  0.41044828]\n",
      " [ 0.65289098  0.34710899]\n",
      " [ 0.65133303  0.34866697]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50061959  0.49938041]\n",
      " [ 0.46733442  0.53266555]\n",
      " [ 0.46540383  0.53459615]\n",
      " [ 0.4965066   0.50349337]\n",
      " [ 0.48125684  0.51874316]\n",
      " [ 0.44468865  0.55531138]\n",
      " [ 0.41739589  0.58260411]\n",
      " [ 0.44666639  0.55333364]\n",
      " [ 0.51946652  0.48053345]\n",
      " [ 0.44543263  0.5545674 ]\n",
      " [ 0.41466555  0.58533448]\n",
      " [ 0.51004905  0.48995101]\n",
      " [ 0.49678817  0.5032118 ]\n",
      " [ 0.53293407  0.46706596]\n",
      " [ 0.54829627  0.4517037 ]\n",
      " [ 0.5266602   0.47333983]\n",
      " [ 0.50233966  0.49766037]\n",
      " [ 0.48865604  0.51134396]\n",
      " [ 0.45176926  0.54823077]\n",
      " [ 0.49041906  0.50958091]\n",
      " [ 0.47712442  0.52287561]\n",
      " [ 0.46104291  0.53895712]\n",
      " [ 0.51110965  0.48889035]\n",
      " [ 0.43415481  0.56584513]\n",
      " [ 0.52825201  0.47174799]\n",
      " [ 0.43550837  0.56449169]\n",
      " [ 0.42477801  0.57522202]\n",
      " [ 0.50729728  0.49270275]\n",
      " [ 0.49304974  0.50695032]\n",
      " [ 0.45958093  0.5404191 ]\n",
      " [ 0.54786634  0.45213374]\n",
      " [ 0.4209576   0.57904238]\n",
      " [ 0.42703256  0.57296747]\n",
      " [ 0.4020099   0.59799004]\n",
      " [ 0.49276447  0.50723553]\n",
      " [ 0.46951005  0.53048998]\n",
      " [ 0.48208007  0.5179199 ]\n",
      " [ 0.55947024  0.44052979]\n",
      " [ 0.46145484  0.53854519]\n",
      " [ 0.45224091  0.54775906]\n",
      " [ 0.48335353  0.5166465 ]\n",
      " [ 0.48600638  0.51399368]\n",
      " [ 0.45831043  0.54168963]\n",
      " [ 0.45651561  0.54348439]\n",
      " [ 0.48382327  0.51617676]\n",
      " [ 0.45861751  0.54138249]\n",
      " [ 0.49531135  0.50468868]\n",
      " [ 0.45012334  0.54987663]\n",
      " [ 0.5512538   0.44874623]\n",
      " [ 0.42689431  0.57310563]\n",
      " [ 0.40139765  0.59860235]\n",
      " [ 0.48700261  0.51299745]\n",
      " [ 0.46984196  0.5301581 ]\n",
      " [ 0.50921547  0.49078453]\n",
      " [ 0.48924243  0.51075757]\n",
      " [ 0.49520633  0.5047937 ]\n",
      " [ 0.44215763  0.55784237]\n",
      " [ 0.4897112   0.51028877]\n",
      " [ 0.53499514  0.46500486]\n",
      " [ 0.43922096  0.56077909]\n",
      " [ 0.45663002  0.54337001]\n",
      " [ 0.47860581  0.52139425]\n",
      " [ 0.43463489  0.5653652 ]\n",
      " [ 0.52369446  0.47630554]\n",
      " [ 0.50526303  0.494737  ]\n",
      " [ 0.43589571  0.56410426]\n",
      " [ 0.48409331  0.51590663]\n",
      " [ 0.5009712   0.4990288 ]\n",
      " [ 0.42260507  0.57739496]\n",
      " [ 0.49582669  0.50417334]\n",
      " [ 0.45503649  0.54496348]\n",
      " [ 0.48275501  0.51724505]\n",
      " [ 0.50700164  0.49299833]\n",
      " [ 0.4934096   0.50659037]\n",
      " [ 0.49271822  0.50728178]\n",
      " [ 0.48676041  0.51323956]\n",
      " [ 0.46757615  0.53242385]\n",
      " [ 0.4898918   0.51010829]\n",
      " [ 0.44909963  0.5509004 ]\n",
      " [ 0.45377767  0.54622239]\n",
      " [ 0.44060501  0.55939502]\n",
      " [ 0.49586725  0.50413275]\n",
      " [ 0.46136591  0.53863406]\n",
      " [ 0.46059737  0.53940266]\n",
      " [ 0.47133663  0.5286634 ]\n",
      " [ 0.4679859   0.53201413]\n",
      " [ 0.4665316   0.53346837]\n",
      " [ 0.46031156  0.53968841]\n",
      " [ 0.52946013  0.47053987]\n",
      " [ 0.50344235  0.49655762]\n",
      " [ 0.45434773  0.54565227]\n",
      " [ 0.47551388  0.52448612]\n",
      " [ 0.57043493  0.42956513]\n",
      " [ 0.41243437  0.5875656 ]\n",
      " [ 0.4255808   0.5744192 ]\n",
      " [ 0.46691746  0.53308254]\n",
      " [ 0.44473267  0.55526727]\n",
      " [ 0.53651971  0.46348026]\n",
      " [ 0.48855028  0.51144969]\n",
      " [ 0.4813326   0.5186674 ]]\n",
      "[[ 0.33149076  0.66850924]\n",
      " [ 0.34671798  0.65328199]\n",
      " [ 0.35472897  0.64527106]\n",
      " [ 0.37732926  0.62267077]\n",
      " [ 0.26039615  0.73960382]\n",
      " [ 0.29056478  0.70943522]\n",
      " [ 0.33336955  0.66663045]\n",
      " [ 0.25261509  0.74738491]\n",
      " [ 0.30831453  0.6916855 ]\n",
      " [ 0.24633075  0.7536692 ]\n",
      " [ 0.29504794  0.70495206]\n",
      " [ 0.34773442  0.65226555]\n",
      " [ 0.37233818  0.62766188]\n",
      " [ 0.2963717   0.7036283 ]\n",
      " [ 0.32200778  0.67799222]\n",
      " [ 0.3368161   0.66318393]\n",
      " [ 0.30492377  0.69507623]\n",
      " [ 0.32966214  0.67033786]\n",
      " [ 0.36026838  0.63973159]\n",
      " [ 0.31691658  0.68308342]\n",
      " [ 0.32083425  0.67916578]\n",
      " [ 0.37184948  0.62815052]\n",
      " [ 0.31391063  0.68608934]\n",
      " [ 0.3540504   0.6459496 ]\n",
      " [ 0.33093596  0.66906399]\n",
      " [ 0.26895157  0.73104841]\n",
      " [ 0.38835874  0.61164129]\n",
      " [ 0.29261976  0.70738024]\n",
      " [ 0.32937312  0.67062694]\n",
      " [ 0.3588773   0.6411227 ]\n",
      " [ 0.28005293  0.71994698]\n",
      " [ 0.2864539   0.71354604]\n",
      " [ 0.28886747  0.71113259]\n",
      " [ 0.2683045   0.73169553]\n",
      " [ 0.3526147   0.6473853 ]\n",
      " [ 0.31285852  0.68714148]\n",
      " [ 0.33924252  0.66075748]\n",
      " [ 0.31007376  0.68992627]\n",
      " [ 0.2821025   0.71789753]\n",
      " [ 0.28043559  0.71956438]\n",
      " [ 0.24238539  0.75761461]\n",
      " [ 0.35345578  0.64654428]\n",
      " [ 0.31525341  0.68474662]\n",
      " [ 0.34406164  0.65593833]\n",
      " [ 0.37077397  0.62922603]\n",
      " [ 0.35478833  0.6452117 ]\n",
      " [ 0.39151913  0.60848081]\n",
      " [ 0.2971395   0.70286053]\n",
      " [ 0.33047447  0.66952556]\n",
      " [ 0.30313212  0.69686782]\n",
      " [ 0.26423636  0.73576367]\n",
      " [ 0.28486344  0.71513659]\n",
      " [ 0.34873962  0.65126038]\n",
      " [ 0.34989592  0.65010399]\n",
      " [ 0.2837486   0.71625137]\n",
      " [ 0.3128247   0.68717533]\n",
      " [ 0.29774231  0.70225763]\n",
      " [ 0.27360347  0.72639662]\n",
      " [ 0.27425683  0.72574311]\n",
      " [ 0.31676438  0.68323559]\n",
      " [ 0.3582308   0.64176923]\n",
      " [ 0.32368249  0.67631751]\n",
      " [ 0.23598382  0.76401627]\n",
      " [ 0.30638951  0.69361043]\n",
      " [ 0.30996653  0.69003344]\n",
      " [ 0.323641    0.67635906]\n",
      " [ 0.29778832  0.70221168]\n",
      " [ 0.3433775   0.65662247]\n",
      " [ 0.35981739  0.64018267]\n",
      " [ 0.25145552  0.74854439]\n",
      " [ 0.32141894  0.67858106]\n",
      " [ 0.26742589  0.73257411]\n",
      " [ 0.34259886  0.65740114]\n",
      " [ 0.28105059  0.71894938]\n",
      " [ 0.38479143  0.61520863]\n",
      " [ 0.28944543  0.71055454]\n",
      " [ 0.28212214  0.71787786]\n",
      " [ 0.2750797   0.72492027]\n",
      " [ 0.28095809  0.71904194]\n",
      " [ 0.26151508  0.73848492]\n",
      " [ 0.35460153  0.6453985 ]\n",
      " [ 0.3598257   0.64017427]\n",
      " [ 0.30536228  0.69463778]\n",
      " [ 0.33049801  0.66950196]\n",
      " [ 0.32964689  0.67035311]\n",
      " [ 0.32376871  0.67623132]\n",
      " [ 0.27432099  0.72567904]\n",
      " [ 0.33451137  0.66548866]\n",
      " [ 0.31480777  0.68519223]\n",
      " [ 0.27900732  0.72099262]\n",
      " [ 0.42440027  0.57559979]\n",
      " [ 0.29408571  0.70591426]\n",
      " [ 0.25079718  0.74920279]\n",
      " [ 0.30409151  0.69590855]\n",
      " [ 0.35434502  0.64565498]\n",
      " [ 0.3343657   0.66563427]\n",
      " [ 0.3316201   0.66837996]\n",
      " [ 0.29892009  0.70107996]\n",
      " [ 0.33804187  0.66195816]\n",
      " [ 0.34029186  0.65970814]]\n",
      "Epoch: 1/1000,   Iteration: 10,   Train loss: 0.818,   10.4s /batch.  \n",
      "[[ 0.28756699  0.71243298]\n",
      " [ 0.28214699  0.71785301]\n",
      " [ 0.38622972  0.61377025]\n",
      " [ 0.31227705  0.68772298]\n",
      " [ 0.29618958  0.70381039]\n",
      " [ 0.37291119  0.62708879]\n",
      " [ 0.29507515  0.70492488]\n",
      " [ 0.3003709   0.69962907]\n",
      " [ 0.28102329  0.71897668]\n",
      " [ 0.22849451  0.77150553]\n",
      " [ 0.24534564  0.75465435]\n",
      " [ 0.29539433  0.70460564]\n",
      " [ 0.26842305  0.73157692]\n",
      " [ 0.2889646   0.71103543]\n",
      " [ 0.29773885  0.70226109]\n",
      " [ 0.34285781  0.65714216]\n",
      " [ 0.26155871  0.73844135]\n",
      " [ 0.23170303  0.76829696]\n",
      " [ 0.29343504  0.70656496]\n",
      " [ 0.30638301  0.69361699]\n",
      " [ 0.30403477  0.69596523]\n",
      " [ 0.27144137  0.7285586 ]\n",
      " [ 0.31890458  0.68109542]\n",
      " [ 0.35729033  0.64270967]\n",
      " [ 0.37963378  0.62036622]\n",
      " [ 0.24163301  0.75836694]\n",
      " [ 0.27239126  0.72760868]\n",
      " [ 0.26043725  0.73956281]\n",
      " [ 0.27496588  0.72503406]\n",
      " [ 0.33423874  0.66576129]\n",
      " [ 0.31454596  0.68545401]\n",
      " [ 0.3115367   0.68846333]\n",
      " [ 0.32090256  0.67909741]\n",
      " [ 0.2470264   0.75297362]\n",
      " [ 0.27341536  0.72658467]\n",
      " [ 0.36975601  0.63024402]\n",
      " [ 0.26096806  0.73903191]\n",
      " [ 0.29557246  0.70442754]\n",
      " [ 0.32702938  0.67297059]\n",
      " [ 0.22061539  0.77938461]\n",
      " [ 0.37215221  0.62784773]\n",
      " [ 0.27772424  0.72227579]\n",
      " [ 0.28803307  0.71196693]\n",
      " [ 0.28251749  0.71748257]\n",
      " [ 0.30066225  0.69933772]\n",
      " [ 0.28585729  0.71414268]\n",
      " [ 0.29085615  0.70914394]\n",
      " [ 0.30277607  0.69722396]\n",
      " [ 0.27706826  0.72293174]\n",
      " [ 0.27975145  0.72024852]\n",
      " [ 0.24221757  0.75778246]\n",
      " [ 0.23515984  0.76484019]\n",
      " [ 0.2808564   0.71914357]\n",
      " [ 0.2778489   0.72215116]\n",
      " [ 0.29306999  0.70692998]\n",
      " [ 0.25982037  0.7401796 ]\n",
      " [ 0.25014099  0.74985898]\n",
      " [ 0.33673221  0.66326779]\n",
      " [ 0.27855691  0.72144312]\n",
      " [ 0.31167772  0.68832225]\n",
      " [ 0.31977361  0.68022645]\n",
      " [ 0.2953535   0.70464653]\n",
      " [ 0.30764067  0.69235939]\n",
      " [ 0.27513525  0.72486478]\n",
      " [ 0.28781155  0.71218848]\n",
      " [ 0.27593163  0.72406828]\n",
      " [ 0.32767427  0.67232573]\n",
      " [ 0.35801673  0.64198327]\n",
      " [ 0.32651821  0.67348182]\n",
      " [ 0.28081763  0.71918237]\n",
      " [ 0.32860675  0.67139322]\n",
      " [ 0.29236323  0.70763677]\n",
      " [ 0.34465542  0.65534461]\n",
      " [ 0.27724165  0.72275835]\n",
      " [ 0.3133755   0.68662447]\n",
      " [ 0.24767934  0.75232059]\n",
      " [ 0.2392966   0.76070338]\n",
      " [ 0.30310661  0.69689345]\n",
      " [ 0.24960573  0.75039428]\n",
      " [ 0.31747454  0.68252546]\n",
      " [ 0.30725503  0.69274497]\n",
      " [ 0.34883782  0.65116227]\n",
      " [ 0.22848603  0.77151394]\n",
      " [ 0.36965916  0.63034081]\n",
      " [ 0.3489494   0.65105057]\n",
      " [ 0.30077913  0.6992209 ]\n",
      " [ 0.31414634  0.68585372]\n",
      " [ 0.31279114  0.68720883]\n",
      " [ 0.21284583  0.78715414]\n",
      " [ 0.27700755  0.72299242]\n",
      " [ 0.31745091  0.68254906]\n",
      " [ 0.25703415  0.74296588]\n",
      " [ 0.26892576  0.73107427]\n",
      " [ 0.27508441  0.7249155 ]\n",
      " [ 0.30453727  0.6954627 ]\n",
      " [ 0.35110235  0.64889765]\n",
      " [ 0.19515517  0.80484486]\n",
      " [ 0.30392703  0.696073  ]\n",
      " [ 0.27924663  0.72075331]\n",
      " [ 0.24288984  0.75711018]]\n",
      "[[ 0.31727406  0.68272591]\n",
      " [ 0.33699843  0.6630016 ]\n",
      " [ 0.45387253  0.5461275 ]\n",
      " [ 0.35737154  0.64262843]\n",
      " [ 0.42717475  0.57282525]\n",
      " [ 0.32607889  0.67392117]\n",
      " [ 0.32049531  0.67950463]\n",
      " [ 0.32478592  0.67521417]\n",
      " [ 0.28505108  0.71494901]\n",
      " [ 0.32188731  0.67811269]\n",
      " [ 0.31206021  0.68793982]\n",
      " [ 0.40572447  0.59427553]\n",
      " [ 0.37532711  0.62467289]\n",
      " [ 0.38218808  0.61781192]\n",
      " [ 0.32325378  0.67674625]\n",
      " [ 0.32478154  0.67521846]\n",
      " [ 0.31843114  0.68156886]\n",
      " [ 0.36604762  0.63395244]\n",
      " [ 0.37613666  0.62386334]\n",
      " [ 0.29310921  0.70689082]\n",
      " [ 0.36927345  0.63072652]\n",
      " [ 0.37991697  0.62008303]\n",
      " [ 0.31917793  0.68082213]\n",
      " [ 0.36012506  0.63987494]\n",
      " [ 0.30685282  0.69314718]\n",
      " [ 0.37090242  0.62909752]\n",
      " [ 0.30816808  0.69183195]\n",
      " [ 0.32029077  0.67970926]\n",
      " [ 0.2632789   0.73672104]\n",
      " [ 0.4280642   0.57193577]\n",
      " [ 0.32599795  0.67400205]\n",
      " [ 0.37957326  0.62042671]\n",
      " [ 0.30680859  0.69319141]\n",
      " [ 0.34640452  0.65359551]\n",
      " [ 0.32845598  0.67154408]\n",
      " [ 0.36102715  0.63897282]\n",
      " [ 0.35304734  0.64695263]\n",
      " [ 0.37726599  0.62273401]\n",
      " [ 0.36551902  0.63448101]\n",
      " [ 0.38191774  0.61808228]\n",
      " [ 0.33414197  0.66585809]\n",
      " [ 0.3661117   0.6338883 ]\n",
      " [ 0.37371063  0.62628937]\n",
      " [ 0.32572863  0.6742714 ]\n",
      " [ 0.33984745  0.66015249]\n",
      " [ 0.37410122  0.62589878]\n",
      " [ 0.30450895  0.69549102]\n",
      " [ 0.27767736  0.72232264]\n",
      " [ 0.33364064  0.66635942]\n",
      " [ 0.4033823   0.5966177 ]\n",
      " [ 0.42465085  0.57534915]\n",
      " [ 0.3065097   0.69349027]\n",
      " [ 0.35352439  0.64647561]\n",
      " [ 0.35105267  0.6489473 ]\n",
      " [ 0.31690246  0.68309754]\n",
      " [ 0.30319774  0.69680226]\n",
      " [ 0.33189976  0.66810018]\n",
      " [ 0.34580779  0.65419215]\n",
      " [ 0.24912478  0.75087517]\n",
      " [ 0.43088931  0.56911075]\n",
      " [ 0.25904822  0.74095178]\n",
      " [ 0.39599898  0.60400093]\n",
      " [ 0.4136171   0.58638287]\n",
      " [ 0.32137808  0.67862189]\n",
      " [ 0.38207239  0.61792761]\n",
      " [ 0.34851295  0.65148705]\n",
      " [ 0.34375021  0.6562497 ]\n",
      " [ 0.33773446  0.66226554]\n",
      " [ 0.36429045  0.63570958]\n",
      " [ 0.31861165  0.68138832]\n",
      " [ 0.37510791  0.62489206]\n",
      " [ 0.35265747  0.64734256]\n",
      " [ 0.30993554  0.69006449]\n",
      " [ 0.36511487  0.63488513]\n",
      " [ 0.34088844  0.65911156]\n",
      " [ 0.29160583  0.70839417]\n",
      " [ 0.34475204  0.65524787]\n",
      " [ 0.34111252  0.65888745]\n",
      " [ 0.32107374  0.67892629]\n",
      " [ 0.3093614   0.6906386 ]\n",
      " [ 0.33295146  0.66704851]\n",
      " [ 0.39798373  0.60201627]\n",
      " [ 0.34678707  0.65321285]\n",
      " [ 0.31983718  0.68016279]\n",
      " [ 0.32807079  0.67192918]\n",
      " [ 0.34828493  0.6517151 ]\n",
      " [ 0.42239335  0.57760668]\n",
      " [ 0.35174385  0.64825612]\n",
      " [ 0.40156448  0.59843552]\n",
      " [ 0.3966583   0.6033417 ]\n",
      " [ 0.38179094  0.61820906]\n",
      " [ 0.32027325  0.67972678]\n",
      " [ 0.36809838  0.63190156]\n",
      " [ 0.35659543  0.6434046 ]\n",
      " [ 0.33367088  0.66632915]\n",
      " [ 0.34691146  0.65308851]\n",
      " [ 0.3583937   0.64160633]\n",
      " [ 0.33845478  0.66154522]\n",
      " [ 0.39808601  0.60191399]\n",
      " [ 0.37547901  0.62452108]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41447106  0.58552891]\n",
      " [ 0.41302839  0.58697164]\n",
      " [ 0.39160332  0.60839665]\n",
      " [ 0.56024587  0.43975413]\n",
      " [ 0.50562459  0.49437544]\n",
      " [ 0.48533827  0.51466173]\n",
      " [ 0.43900681  0.56099325]\n",
      " [ 0.43379524  0.56620479]\n",
      " [ 0.39913243  0.60086757]\n",
      " [ 0.40233526  0.59766477]\n",
      " [ 0.37407175  0.62592828]\n",
      " [ 0.66726202  0.33273795]\n",
      " [ 0.47582155  0.52417845]\n",
      " [ 0.4610649   0.53893507]\n",
      " [ 0.50722975  0.49277028]\n",
      " [ 0.45089808  0.54910189]\n",
      " [ 0.50157976  0.49842018]\n",
      " [ 0.42787898  0.57212102]\n",
      " [ 0.40172255  0.59827739]\n",
      " [ 0.53015745  0.46984249]\n",
      " [ 0.48957822  0.51042181]\n",
      " [ 0.42061257  0.57938737]\n",
      " [ 0.39652199  0.60347801]\n",
      " [ 0.44456166  0.5554384 ]\n",
      " [ 0.49810433  0.50189567]\n",
      " [ 0.48988754  0.51011246]\n",
      " [ 0.46566454  0.53433549]\n",
      " [ 0.38571653  0.61428356]\n",
      " [ 0.41622791  0.58377206]\n",
      " [ 0.40130928  0.59869063]\n",
      " [ 0.40365753  0.59634238]\n",
      " [ 0.4440248   0.5559752 ]\n",
      " [ 0.43364647  0.5663535 ]\n",
      " [ 0.34800562  0.65199441]\n",
      " [ 0.47425091  0.52574909]\n",
      " [ 0.5288139   0.47118613]\n",
      " [ 0.43532574  0.5646742 ]\n",
      " [ 0.36520043  0.6347996 ]\n",
      " [ 0.37642449  0.62357551]\n",
      " [ 0.44467479  0.55532521]\n",
      " [ 0.43897796  0.5610221 ]\n",
      " [ 0.43504176  0.56495827]\n",
      " [ 0.46174374  0.53825623]\n",
      " [ 0.50377339  0.49622664]\n",
      " [ 0.46441853  0.53558147]\n",
      " [ 0.46265113  0.53734887]\n",
      " [ 0.41339535  0.5866046 ]\n",
      " [ 0.50725597  0.492744  ]\n",
      " [ 0.39392021  0.60607982]\n",
      " [ 0.42588967  0.57411033]\n",
      " [ 0.57298446  0.42701548]\n",
      " [ 0.45250049  0.54749954]\n",
      " [ 0.51188904  0.48811099]\n",
      " [ 0.39947248  0.60052752]\n",
      " [ 0.56577051  0.43422949]\n",
      " [ 0.42158201  0.57841796]\n",
      " [ 0.43327749  0.56672245]\n",
      " [ 0.47765142  0.52234858]\n",
      " [ 0.39196622  0.60803378]\n",
      " [ 0.4137857   0.5862143 ]\n",
      " [ 0.42266992  0.57733011]\n",
      " [ 0.44978774  0.55021226]\n",
      " [ 0.51446778  0.48553225]\n",
      " [ 0.43246379  0.56753618]\n",
      " [ 0.4305824   0.56941754]\n",
      " [ 0.44138679  0.55861318]\n",
      " [ 0.46327329  0.53672671]\n",
      " [ 0.48603895  0.51396114]\n",
      " [ 0.42034796  0.57965207]\n",
      " [ 0.46497703  0.53502297]\n",
      " [ 0.43737337  0.56262654]\n",
      " [ 0.39641199  0.60358799]\n",
      " [ 0.40445438  0.59554565]\n",
      " [ 0.36592281  0.63407719]\n",
      " [ 0.47504196  0.52495795]\n",
      " [ 0.44952819  0.55047178]\n",
      " [ 0.37554502  0.62445492]\n",
      " [ 0.47209165  0.52790833]\n",
      " [ 0.43882969  0.56117034]\n",
      " [ 0.37187505  0.62812501]\n",
      " [ 0.44604069  0.55395931]\n",
      " [ 0.42166919  0.57833076]\n",
      " [ 0.41667086  0.58332908]\n",
      " [ 0.46485183  0.53514814]\n",
      " [ 0.49778578  0.50221425]\n",
      " [ 0.4515751   0.5484249 ]\n",
      " [ 0.43916711  0.56083286]\n",
      " [ 0.41455033  0.58544964]\n",
      " [ 0.44386688  0.55613309]\n",
      " [ 0.42433402  0.57566595]\n",
      " [ 0.52415317  0.47584683]\n",
      " [ 0.38780162  0.61219841]\n",
      " [ 0.50965768  0.49034229]\n",
      " [ 0.37223256  0.62776744]\n",
      " [ 0.43640703  0.56359297]\n",
      " [ 0.48453543  0.5154646 ]\n",
      " [ 0.42320701  0.57679302]\n",
      " [ 0.4746289   0.52537107]\n",
      " [ 0.43018591  0.56981409]\n",
      " [ 0.46930614  0.53069389]]\n",
      "[[ 0.6209619   0.3790381 ]\n",
      " [ 0.59552968  0.40447029]\n",
      " [ 0.56097889  0.43902108]\n",
      " [ 0.5624938   0.43750617]\n",
      " [ 0.50586301  0.49413699]\n",
      " [ 0.62578607  0.37421399]\n",
      " [ 0.59443909  0.40556085]\n",
      " [ 0.54417002  0.45583004]\n",
      " [ 0.62430251  0.37569749]\n",
      " [ 0.63800073  0.36199927]\n",
      " [ 0.61030263  0.38969746]\n",
      " [ 0.50707185  0.49292812]\n",
      " [ 0.5504728   0.44952714]\n",
      " [ 0.5706439   0.4293561 ]\n",
      " [ 0.57554322  0.42445678]\n",
      " [ 0.53764659  0.46235344]\n",
      " [ 0.53943282  0.46056721]\n",
      " [ 0.57506567  0.42493433]\n",
      " [ 0.56250608  0.43749398]\n",
      " [ 0.54068011  0.45931986]\n",
      " [ 0.71812564  0.28187436]\n",
      " [ 0.6706059   0.32939413]\n",
      " [ 0.57635057  0.42364943]\n",
      " [ 0.52136171  0.47863832]\n",
      " [ 0.48083112  0.51916885]\n",
      " [ 0.58108652  0.41891348]\n",
      " [ 0.55757284  0.4424271 ]\n",
      " [ 0.57144588  0.42855418]\n",
      " [ 0.60860264  0.39139739]\n",
      " [ 0.53531092  0.46468905]\n",
      " [ 0.58918631  0.41081366]\n",
      " [ 0.52265978  0.47734028]\n",
      " [ 0.60065103  0.399349  ]\n",
      " [ 0.55163962  0.44836044]\n",
      " [ 0.54250121  0.45749876]\n",
      " [ 0.60713899  0.39286101]\n",
      " [ 0.52603203  0.47396797]\n",
      " [ 0.53768402  0.46231598]\n",
      " [ 0.74026215  0.25973779]\n",
      " [ 0.55343622  0.44656375]\n",
      " [ 0.58866501  0.41133496]\n",
      " [ 0.54276109  0.45723891]\n",
      " [ 0.57646078  0.42353919]\n",
      " [ 0.54361516  0.45638487]\n",
      " [ 0.59119904  0.40880093]\n",
      " [ 0.53877753  0.46122244]\n",
      " [ 0.56934404  0.43065596]\n",
      " [ 0.56547236  0.43452761]\n",
      " [ 0.52788526  0.47211474]\n",
      " [ 0.7548517   0.2451483 ]\n",
      " [ 0.61740023  0.38259977]\n",
      " [ 0.52820617  0.4717938 ]\n",
      " [ 0.62540209  0.37459794]\n",
      " [ 0.50819397  0.49180603]\n",
      " [ 0.53777736  0.4622227 ]\n",
      " [ 0.68237591  0.31762415]\n",
      " [ 0.56853896  0.4314611 ]\n",
      " [ 0.53097403  0.46902591]\n",
      " [ 0.54237163  0.45762843]\n",
      " [ 0.55605763  0.44394234]\n",
      " [ 0.59199423  0.40800577]\n",
      " [ 0.53577024  0.46422973]\n",
      " [ 0.50879854  0.49120143]\n",
      " [ 0.55208927  0.44791073]\n",
      " [ 0.57085967  0.42914036]\n",
      " [ 0.58752322  0.41247684]\n",
      " [ 0.54787338  0.45212662]\n",
      " [ 0.65059572  0.34940428]\n",
      " [ 0.57069266  0.42930734]\n",
      " [ 0.57204002  0.42796001]\n",
      " [ 0.60499209  0.39500791]\n",
      " [ 0.65853095  0.34146908]\n",
      " [ 0.54151005  0.45848995]\n",
      " [ 0.57247978  0.42752028]\n",
      " [ 0.55442649  0.44557348]\n",
      " [ 0.47243834  0.52756166]\n",
      " [ 0.6040352   0.39596474]\n",
      " [ 0.58715737  0.41284269]\n",
      " [ 0.61344177  0.38655826]\n",
      " [ 0.56726527  0.4327347 ]\n",
      " [ 0.5188722   0.48112777]\n",
      " [ 0.54224664  0.4577533 ]\n",
      " [ 0.55646169  0.44353834]\n",
      " [ 0.63242322  0.36757675]\n",
      " [ 0.62541187  0.37458813]\n",
      " [ 0.51440901  0.48559093]\n",
      " [ 0.51437116  0.48562884]\n",
      " [ 0.55003691  0.44996309]\n",
      " [ 0.56496727  0.4350327 ]\n",
      " [ 0.58224571  0.41775435]\n",
      " [ 0.57809329  0.42190665]\n",
      " [ 0.58057505  0.41942495]\n",
      " [ 0.52076614  0.47923383]\n",
      " [ 0.57081354  0.42918655]\n",
      " [ 0.49449494  0.50550508]\n",
      " [ 0.5253343   0.47466579]\n",
      " [ 0.59274578  0.40725428]\n",
      " [ 0.64107507  0.35892493]\n",
      " [ 0.55081743  0.44918257]\n",
      " [ 0.62769765  0.37230232]]\n",
      "[[ 0.55733055  0.44266954]\n",
      " [ 0.72593957  0.2740604 ]\n",
      " [ 0.62838221  0.37161788]\n",
      " [ 0.58519888  0.41480118]\n",
      " [ 0.62003422  0.37996581]\n",
      " [ 0.57756758  0.42243239]\n",
      " [ 0.58143586  0.41856411]\n",
      " [ 0.58025938  0.41974065]\n",
      " [ 0.62154883  0.37845114]\n",
      " [ 0.64744002  0.35255998]\n",
      " [ 0.61376244  0.38623756]\n",
      " [ 0.57968229  0.42031771]\n",
      " [ 0.63621384  0.36378619]\n",
      " [ 0.59915102  0.40084893]\n",
      " [ 0.59788364  0.40211633]\n",
      " [ 0.6013332   0.39866677]\n",
      " [ 0.53070486  0.46929511]\n",
      " [ 0.61583316  0.38416693]\n",
      " [ 0.62596714  0.37403288]\n",
      " [ 0.59984535  0.40015462]\n",
      " [ 0.5945667   0.40543327]\n",
      " [ 0.6256206   0.37437943]\n",
      " [ 0.57827687  0.42172313]\n",
      " [ 0.61497551  0.38502449]\n",
      " [ 0.45952475  0.54047525]\n",
      " [ 0.60070395  0.39929602]\n",
      " [ 0.6940816   0.30591834]\n",
      " [ 0.5850175   0.41498256]\n",
      " [ 0.59715796  0.40284204]\n",
      " [ 0.4665235   0.53347653]\n",
      " [ 0.56424552  0.43575448]\n",
      " [ 0.62879705  0.37120292]\n",
      " [ 0.63620561  0.3637943 ]\n",
      " [ 0.54806149  0.45193857]\n",
      " [ 0.56028175  0.43971819]\n",
      " [ 0.6037609   0.39623907]\n",
      " [ 0.60050291  0.39949706]\n",
      " [ 0.60664928  0.39335075]\n",
      " [ 0.56933886  0.43066117]\n",
      " [ 0.71131301  0.28868696]\n",
      " [ 0.63108993  0.3689101 ]\n",
      " [ 0.5670886   0.43291137]\n",
      " [ 0.60441869  0.39558131]\n",
      " [ 0.64205235  0.35794765]\n",
      " [ 0.58346218  0.41653779]\n",
      " [ 0.62486559  0.37513438]\n",
      " [ 0.57245153  0.42754847]\n",
      " [ 0.68228304  0.31771693]\n",
      " [ 0.55318618  0.44681379]\n",
      " [ 0.61929643  0.38070357]\n",
      " [ 0.6134032   0.38659677]\n",
      " [ 0.64683473  0.3531653 ]\n",
      " [ 0.73234957  0.26765046]\n",
      " [ 0.50599813  0.49400187]\n",
      " [ 0.56919038  0.43080965]\n",
      " [ 0.62861562  0.37138441]\n",
      " [ 0.61242771  0.38757229]\n",
      " [ 0.69335753  0.30664247]\n",
      " [ 0.67179012  0.32820991]\n",
      " [ 0.58070529  0.41929477]\n",
      " [ 0.66355681  0.33644319]\n",
      " [ 0.61418313  0.38581684]\n",
      " [ 0.59905756  0.40094239]\n",
      " [ 0.58609009  0.41390997]\n",
      " [ 0.66816205  0.33183798]\n",
      " [ 0.63928157  0.3607184 ]\n",
      " [ 0.59553403  0.40446597]\n",
      " [ 0.62417662  0.37582341]\n",
      " [ 0.6112231   0.38877693]\n",
      " [ 0.59048456  0.40951547]\n",
      " [ 0.5623706   0.43762937]\n",
      " [ 0.58610976  0.41389027]\n",
      " [ 0.56339049  0.43660957]\n",
      " [ 0.57657033  0.4234297 ]\n",
      " [ 0.6092757   0.39072427]\n",
      " [ 0.63989687  0.36010316]\n",
      " [ 0.60173768  0.39826241]\n",
      " [ 0.62109059  0.37890941]\n",
      " [ 0.55859333  0.44140664]\n",
      " [ 0.52960283  0.47039717]\n",
      " [ 0.56843257  0.4315674 ]\n",
      " [ 0.68583566  0.31416431]\n",
      " [ 0.59490258  0.40509748]\n",
      " [ 0.60406917  0.39593092]\n",
      " [ 0.66155827  0.33844176]\n",
      " [ 0.58786327  0.4121367 ]\n",
      " [ 0.65058249  0.34941751]\n",
      " [ 0.54126149  0.45873857]\n",
      " [ 0.58698547  0.41301459]\n",
      " [ 0.64028335  0.35971665]\n",
      " [ 0.517775    0.48222509]\n",
      " [ 0.6126976   0.38730246]\n",
      " [ 0.60429585  0.39570421]\n",
      " [ 0.63326538  0.36673468]\n",
      " [ 0.581981    0.41801906]\n",
      " [ 0.50983304  0.49016693]\n",
      " [ 0.62348026  0.37651974]\n",
      " [ 0.68847775  0.31152222]\n",
      " [ 0.52516121  0.47483885]\n",
      " [ 0.57530135  0.42469868]]\n",
      "Epoch: 1/1000,   Iteration: 15,   Train loss: 0.721,   10.7s /batch.  \n",
      "[[ 0.62791228  0.37208775]\n",
      " [ 0.56317604  0.43682402]\n",
      " [ 0.64824319  0.35175678]\n",
      " [ 0.63719285  0.36280712]\n",
      " [ 0.52758855  0.47241142]\n",
      " [ 0.63470858  0.36529145]\n",
      " [ 0.59909391  0.40090612]\n",
      " [ 0.57984191  0.42015806]\n",
      " [ 0.57539219  0.42460775]\n",
      " [ 0.5669418   0.43305817]\n",
      " [ 0.65296817  0.34703177]\n",
      " [ 0.55866766  0.44133234]\n",
      " [ 0.65436828  0.34563172]\n",
      " [ 0.55903643  0.44096351]\n",
      " [ 0.57447207  0.4255279 ]\n",
      " [ 0.56114519  0.43885478]\n",
      " [ 0.57420677  0.42579323]\n",
      " [ 0.63754529  0.36245471]\n",
      " [ 0.62776482  0.37223521]\n",
      " [ 0.57593614  0.42406386]\n",
      " [ 0.54733092  0.45266908]\n",
      " [ 0.58945727  0.41054276]\n",
      " [ 0.57021362  0.42978638]\n",
      " [ 0.66318226  0.33681774]\n",
      " [ 0.59237516  0.40762484]\n",
      " [ 0.56182212  0.43817779]\n",
      " [ 0.58673263  0.41326731]\n",
      " [ 0.60548002  0.39452001]\n",
      " [ 0.50714535  0.49285465]\n",
      " [ 0.59283829  0.40716168]\n",
      " [ 0.61730874  0.38269123]\n",
      " [ 0.52124411  0.47875583]\n",
      " [ 0.60260755  0.39739242]\n",
      " [ 0.63650763  0.36349237]\n",
      " [ 0.59409571  0.40590432]\n",
      " [ 0.59882098  0.40117896]\n",
      " [ 0.6521616   0.3478384 ]\n",
      " [ 0.60911351  0.39088655]\n",
      " [ 0.62683225  0.37316769]\n",
      " [ 0.57746893  0.42253104]\n",
      " [ 0.61411244  0.3858875 ]\n",
      " [ 0.51630151  0.48369852]\n",
      " [ 0.55453074  0.44546926]\n",
      " [ 0.65000087  0.34999913]\n",
      " [ 0.57406825  0.42593178]\n",
      " [ 0.66287315  0.33712688]\n",
      " [ 0.59281087  0.4071891 ]\n",
      " [ 0.60880923  0.3911908 ]\n",
      " [ 0.51728666  0.48271328]\n",
      " [ 0.6233713   0.3766287 ]\n",
      " [ 0.64112198  0.35887799]\n",
      " [ 0.65431184  0.34568819]\n",
      " [ 0.5733723   0.42662767]\n",
      " [ 0.66212976  0.33787021]\n",
      " [ 0.50823873  0.49176127]\n",
      " [ 0.60684711  0.39315289]\n",
      " [ 0.69265246  0.30734757]\n",
      " [ 0.70468277  0.2953172 ]\n",
      " [ 0.68481106  0.31518894]\n",
      " [ 0.60087621  0.39912376]\n",
      " [ 0.60957682  0.39042318]\n",
      " [ 0.53851837  0.46148169]\n",
      " [ 0.57746339  0.42253661]\n",
      " [ 0.61466444  0.38533559]\n",
      " [ 0.59258556  0.40741444]\n",
      " [ 0.65246671  0.34753326]\n",
      " [ 0.62427372  0.37572631]\n",
      " [ 0.55751497  0.442485  ]\n",
      " [ 0.62553489  0.37446514]\n",
      " [ 0.61422372  0.38577634]\n",
      " [ 0.55874783  0.44125217]\n",
      " [ 0.54739052  0.45260948]\n",
      " [ 0.56538635  0.43461367]\n",
      " [ 0.53026742  0.46973261]\n",
      " [ 0.69648021  0.30351985]\n",
      " [ 0.53406733  0.46593267]\n",
      " [ 0.62040794  0.379592  ]\n",
      " [ 0.58898085  0.41101915]\n",
      " [ 0.55006832  0.44993165]\n",
      " [ 0.68835789  0.31164211]\n",
      " [ 0.6307348   0.36926523]\n",
      " [ 0.53244698  0.46755302]\n",
      " [ 0.59086055  0.40913939]\n",
      " [ 0.65984231  0.34015766]\n",
      " [ 0.54924387  0.45075616]\n",
      " [ 0.59752363  0.40247637]\n",
      " [ 0.68584102  0.31415898]\n",
      " [ 0.60463893  0.39536101]\n",
      " [ 0.63981599  0.36018404]\n",
      " [ 0.66284949  0.33715054]\n",
      " [ 0.72607982  0.27392012]\n",
      " [ 0.60318023  0.39681974]\n",
      " [ 0.64063096  0.35936907]\n",
      " [ 0.54759049  0.45240951]\n",
      " [ 0.57060307  0.42939693]\n",
      " [ 0.5615328   0.43846714]\n",
      " [ 0.66000813  0.33999196]\n",
      " [ 0.58883274  0.41116729]\n",
      " [ 0.60435367  0.39564633]\n",
      " [ 0.61890173  0.38109827]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.56334084  0.43665913]\n",
      " [ 0.54523057  0.45476937]\n",
      " [ 0.56745875  0.43254116]\n",
      " [ 0.49754325  0.50245684]\n",
      " [ 0.53175193  0.46824813]\n",
      " [ 0.53631437  0.46368557]\n",
      " [ 0.59011847  0.40988162]\n",
      " [ 0.66123813  0.33876184]\n",
      " [ 0.55974978  0.44025019]\n",
      " [ 0.59361434  0.4063856 ]\n",
      " [ 0.56537187  0.43462816]\n",
      " [ 0.60958177  0.39041826]\n",
      " [ 0.54752016  0.45247978]\n",
      " [ 0.52980119  0.47019887]\n",
      " [ 0.60519433  0.39480564]\n",
      " [ 0.52118796  0.47881201]\n",
      " [ 0.54678583  0.45321414]\n",
      " [ 0.59422946  0.40577048]\n",
      " [ 0.6763311   0.32366881]\n",
      " [ 0.54535419  0.45464572]\n",
      " [ 0.5338794   0.4661206 ]\n",
      " [ 0.57784241  0.42215762]\n",
      " [ 0.53465164  0.46534842]\n",
      " [ 0.51693982  0.48306015]\n",
      " [ 0.51751035  0.48248962]\n",
      " [ 0.5544408   0.4455592 ]\n",
      " [ 0.62153977  0.3784602 ]\n",
      " [ 0.54367548  0.45632449]\n",
      " [ 0.54794848  0.45205152]\n",
      " [ 0.47033942  0.52966058]\n",
      " [ 0.61978292  0.38021713]\n",
      " [ 0.53950471  0.4604952 ]\n",
      " [ 0.55886775  0.44113231]\n",
      " [ 0.55171621  0.44828379]\n",
      " [ 0.54191142  0.45808861]\n",
      " [ 0.55914086  0.44085914]\n",
      " [ 0.60106528  0.39893469]\n",
      " [ 0.54692781  0.45307216]\n",
      " [ 0.68624914  0.31375086]\n",
      " [ 0.46637636  0.5336237 ]\n",
      " [ 0.56314772  0.43685225]\n",
      " [ 0.57062036  0.42937958]\n",
      " [ 0.56028908  0.43971092]\n",
      " [ 0.5460937   0.4539063 ]\n",
      " [ 0.56227022  0.43772975]\n",
      " [ 0.59315401  0.40684596]\n",
      " [ 0.54802817  0.45197186]\n",
      " [ 0.68881339  0.31118661]\n",
      " [ 0.53452092  0.46547911]\n",
      " [ 0.54109967  0.45890027]\n",
      " [ 0.51307708  0.48692292]\n",
      " [ 0.57857901  0.42142102]\n",
      " [ 0.54651988  0.45348018]\n",
      " [ 0.60879809  0.39120194]\n",
      " [ 0.59513545  0.40486458]\n",
      " [ 0.49010596  0.50989401]\n",
      " [ 0.53997433  0.46002561]\n",
      " [ 0.5189749   0.48102504]\n",
      " [ 0.4732371   0.52676284]\n",
      " [ 0.52063078  0.47936928]\n",
      " [ 0.56865853  0.43134153]\n",
      " [ 0.51364535  0.48635468]\n",
      " [ 0.51395613  0.48604393]\n",
      " [ 0.57582659  0.42417344]\n",
      " [ 0.5724321   0.42756793]\n",
      " [ 0.54117578  0.45882425]\n",
      " [ 0.5608238   0.43917626]\n",
      " [ 0.52421749  0.47578251]\n",
      " [ 0.54937047  0.45062953]\n",
      " [ 0.52925491  0.47074509]\n",
      " [ 0.57453036  0.42546964]\n",
      " [ 0.53170246  0.46829751]\n",
      " [ 0.50147206  0.49852794]\n",
      " [ 0.61562264  0.38437739]\n",
      " [ 0.59125644  0.40874359]\n",
      " [ 0.55322945  0.44677052]\n",
      " [ 0.53171754  0.46828246]\n",
      " [ 0.57401478  0.42598528]\n",
      " [ 0.55226362  0.44773635]\n",
      " [ 0.62039077  0.37960926]\n",
      " [ 0.54582578  0.45417419]\n",
      " [ 0.53837532  0.46162465]\n",
      " [ 0.60796374  0.39203623]\n",
      " [ 0.52719504  0.47280499]\n",
      " [ 0.56243348  0.43756649]\n",
      " [ 0.53502196  0.46497807]\n",
      " [ 0.56501228  0.43498778]\n",
      " [ 0.56416547  0.4358345 ]\n",
      " [ 0.59403187  0.40596813]\n",
      " [ 0.55330223  0.44669786]\n",
      " [ 0.56950212  0.43049788]\n",
      " [ 0.5830887   0.41691127]\n",
      " [ 0.5523324   0.44766757]\n",
      " [ 0.60813981  0.39186019]\n",
      " [ 0.52835673  0.47164324]\n",
      " [ 0.52561045  0.47438958]\n",
      " [ 0.55502468  0.44497532]\n",
      " [ 0.62896717  0.37103283]\n",
      " [ 0.54393876  0.45606124]\n",
      " [ 0.55671489  0.44328517]]\n",
      "[[ 0.52907395  0.47092602]\n",
      " [ 0.65822005  0.34177989]\n",
      " [ 0.37952936  0.62047064]\n",
      " [ 0.47332749  0.52667248]\n",
      " [ 0.5822739   0.41772613]\n",
      " [ 0.5231207   0.47687933]\n",
      " [ 0.50046563  0.49953437]\n",
      " [ 0.49955237  0.50044769]\n",
      " [ 0.57189798  0.42810193]\n",
      " [ 0.65836495  0.34163502]\n",
      " [ 0.49306151  0.50693852]\n",
      " [ 0.53201771  0.46798226]\n",
      " [ 0.52802932  0.47197062]\n",
      " [ 0.64511555  0.35488439]\n",
      " [ 0.50875765  0.49124232]\n",
      " [ 0.56287521  0.43712479]\n",
      " [ 0.52427399  0.47572604]\n",
      " [ 0.4983581   0.50164187]\n",
      " [ 0.5044412   0.49555883]\n",
      " [ 0.57427442  0.42572558]\n",
      " [ 0.53711987  0.46288007]\n",
      " [ 0.54983252  0.45016751]\n",
      " [ 0.50309247  0.49690753]\n",
      " [ 0.52344161  0.47655836]\n",
      " [ 0.53854543  0.4614546 ]\n",
      " [ 0.5661369   0.43386313]\n",
      " [ 0.48500827  0.5149917 ]\n",
      " [ 0.52424157  0.47575846]\n",
      " [ 0.49714425  0.50285572]\n",
      " [ 0.50327855  0.49672145]\n",
      " [ 0.49865803  0.501342  ]\n",
      " [ 0.53765726  0.4623428 ]\n",
      " [ 0.54471487  0.45528513]\n",
      " [ 0.60700554  0.39299449]\n",
      " [ 0.54335916  0.45664084]\n",
      " [ 0.52061737  0.4793826 ]\n",
      " [ 0.5376792   0.4623208 ]\n",
      " [ 0.60400659  0.39599338]\n",
      " [ 0.47916594  0.52083403]\n",
      " [ 0.5688833   0.4311167 ]\n",
      " [ 0.55932206  0.440678  ]\n",
      " [ 0.51801133  0.48198864]\n",
      " [ 0.60418886  0.39581111]\n",
      " [ 0.47654861  0.52345139]\n",
      " [ 0.52738917  0.47261086]\n",
      " [ 0.47861296  0.52138698]\n",
      " [ 0.52267843  0.47732159]\n",
      " [ 0.48661515  0.51338488]\n",
      " [ 0.50719875  0.49280122]\n",
      " [ 0.51904076  0.48095918]\n",
      " [ 0.5792464   0.42075354]\n",
      " [ 0.54930729  0.45069271]\n",
      " [ 0.53166109  0.46833891]\n",
      " [ 0.55109888  0.44890118]\n",
      " [ 0.50525749  0.49474254]\n",
      " [ 0.49901384  0.50098622]\n",
      " [ 0.53972417  0.46027589]\n",
      " [ 0.53946006  0.46053994]\n",
      " [ 0.51420456  0.48579544]\n",
      " [ 0.52340007  0.47659999]\n",
      " [ 0.51727509  0.48272488]\n",
      " [ 0.51679921  0.48320079]\n",
      " [ 0.53336847  0.46663153]\n",
      " [ 0.54359484  0.45640519]\n",
      " [ 0.55115163  0.4488484 ]\n",
      " [ 0.49422199  0.50577801]\n",
      " [ 0.47759846  0.52240163]\n",
      " [ 0.50054139  0.49945867]\n",
      " [ 0.55199426  0.4480058 ]\n",
      " [ 0.45549718  0.54450285]\n",
      " [ 0.5199672   0.48003277]\n",
      " [ 0.49864444  0.50135553]\n",
      " [ 0.53292316  0.46707678]\n",
      " [ 0.55741364  0.44258639]\n",
      " [ 0.44585565  0.55414438]\n",
      " [ 0.53993922  0.46006078]\n",
      " [ 0.61103147  0.38896853]\n",
      " [ 0.51480782  0.48519218]\n",
      " [ 0.49976793  0.50023204]\n",
      " [ 0.53558534  0.4644146 ]\n",
      " [ 0.59720719  0.40279281]\n",
      " [ 0.50458437  0.49541569]\n",
      " [ 0.53266591  0.46733412]\n",
      " [ 0.52682072  0.47317928]\n",
      " [ 0.50667286  0.49332708]\n",
      " [ 0.51160693  0.4883931 ]\n",
      " [ 0.59432793  0.4056721 ]\n",
      " [ 0.54844475  0.45155522]\n",
      " [ 0.52022296  0.47977707]\n",
      " [ 0.54569024  0.45430976]\n",
      " [ 0.51543647  0.4845635 ]\n",
      " [ 0.53717721  0.46282277]\n",
      " [ 0.50837004  0.49162993]\n",
      " [ 0.49006614  0.50993389]\n",
      " [ 0.41972244  0.58027762]\n",
      " [ 0.44030824  0.55969173]\n",
      " [ 0.5284965   0.47150353]\n",
      " [ 0.46965012  0.53034991]\n",
      " [ 0.49140939  0.50859058]\n",
      " [ 0.56308359  0.43691632]]\n",
      "[[ 0.53797972  0.46202028]\n",
      " [ 0.54080427  0.45919573]\n",
      " [ 0.43472517  0.56527483]\n",
      " [ 0.52067798  0.47932199]\n",
      " [ 0.48501867  0.51498133]\n",
      " [ 0.46361357  0.53638649]\n",
      " [ 0.50447053  0.49552953]\n",
      " [ 0.43253446  0.56746554]\n",
      " [ 0.39512783  0.60487217]\n",
      " [ 0.4840087   0.51599127]\n",
      " [ 0.50650275  0.49349728]\n",
      " [ 0.58717555  0.41282451]\n",
      " [ 0.50321549  0.49678457]\n",
      " [ 0.36465451  0.63534552]\n",
      " [ 0.45443904  0.54556096]\n",
      " [ 0.43312839  0.56687158]\n",
      " [ 0.43638134  0.56361866]\n",
      " [ 0.43540207  0.56459796]\n",
      " [ 0.50548267  0.49451736]\n",
      " [ 0.47967163  0.52032834]\n",
      " [ 0.40193459  0.59806544]\n",
      " [ 0.51184863  0.48815134]\n",
      " [ 0.59637046  0.40362957]\n",
      " [ 0.3781043   0.62189567]\n",
      " [ 0.42571342  0.57428664]\n",
      " [ 0.42312378  0.57687628]\n",
      " [ 0.45911717  0.54088283]\n",
      " [ 0.4871735   0.5128265 ]\n",
      " [ 0.44677052  0.55322945]\n",
      " [ 0.38150886  0.61849117]\n",
      " [ 0.40978366  0.59021634]\n",
      " [ 0.50268757  0.49731249]\n",
      " [ 0.45819798  0.54180205]\n",
      " [ 0.43358696  0.56641304]\n",
      " [ 0.52727383  0.4727262 ]\n",
      " [ 0.46737301  0.53262699]\n",
      " [ 0.4291949   0.57080507]\n",
      " [ 0.43135029  0.56864971]\n",
      " [ 0.46442664  0.53557342]\n",
      " [ 0.41127408  0.58872598]\n",
      " [ 0.46173969  0.53826034]\n",
      " [ 0.51528126  0.48471874]\n",
      " [ 0.43695238  0.56304759]\n",
      " [ 0.45260271  0.54739732]\n",
      " [ 0.56757778  0.43242225]\n",
      " [ 0.55361128  0.44638875]\n",
      " [ 0.51054347  0.48945653]\n",
      " [ 0.59286076  0.40713924]\n",
      " [ 0.40681806  0.59318191]\n",
      " [ 0.39133042  0.60866952]\n",
      " [ 0.51057613  0.48942378]\n",
      " [ 0.44206744  0.55793256]\n",
      " [ 0.44601932  0.55398065]\n",
      " [ 0.49746314  0.50253689]\n",
      " [ 0.54321259  0.45678747]\n",
      " [ 0.42659563  0.57340437]\n",
      " [ 0.50225067  0.4977493 ]\n",
      " [ 0.5134303   0.48656973]\n",
      " [ 0.44109401  0.55890596]\n",
      " [ 0.39088756  0.60911244]\n",
      " [ 0.36007747  0.63992256]\n",
      " [ 0.47331193  0.5266881 ]\n",
      " [ 0.5036214   0.4963786 ]\n",
      " [ 0.35793805  0.64206189]\n",
      " [ 0.43906838  0.56093162]\n",
      " [ 0.48502651  0.51497352]\n",
      " [ 0.4883028   0.51169717]\n",
      " [ 0.47282371  0.52717626]\n",
      " [ 0.42869335  0.57130665]\n",
      " [ 0.51562828  0.48437178]\n",
      " [ 0.36658743  0.63341254]\n",
      " [ 0.54173648  0.45826352]\n",
      " [ 0.42756468  0.57243532]\n",
      " [ 0.44675294  0.55324709]\n",
      " [ 0.4900634   0.50993651]\n",
      " [ 0.38101166  0.61898834]\n",
      " [ 0.41253558  0.58746445]\n",
      " [ 0.50138259  0.49861741]\n",
      " [ 0.43617797  0.56382203]\n",
      " [ 0.42966861  0.57033145]\n",
      " [ 0.45320216  0.54679781]\n",
      " [ 0.47613126  0.5238688 ]\n",
      " [ 0.50906533  0.49093458]\n",
      " [ 0.53570634  0.46429366]\n",
      " [ 0.45212084  0.54787916]\n",
      " [ 0.45513225  0.54486775]\n",
      " [ 0.47029629  0.52970374]\n",
      " [ 0.59073359  0.40926644]\n",
      " [ 0.44919872  0.55080128]\n",
      " [ 0.45819965  0.54180032]\n",
      " [ 0.4850947   0.51490533]\n",
      " [ 0.44147858  0.55852145]\n",
      " [ 0.47491223  0.52508777]\n",
      " [ 0.4533526   0.54664743]\n",
      " [ 0.47858864  0.5214113 ]\n",
      " [ 0.32622397  0.67377597]\n",
      " [ 0.49133915  0.50866091]\n",
      " [ 0.46319449  0.53680551]\n",
      " [ 0.47734234  0.52265763]\n",
      " [ 0.42751154  0.57248843]]\n",
      "[[ 0.43305898  0.56694096]\n",
      " [ 0.39380196  0.60619801]\n",
      " [ 0.43937889  0.56062114]\n",
      " [ 0.4031873   0.59681278]\n",
      " [ 0.4167268   0.58327323]\n",
      " [ 0.35152915  0.64847088]\n",
      " [ 0.50049329  0.49950668]\n",
      " [ 0.38495338  0.61504668]\n",
      " [ 0.43604571  0.56395429]\n",
      " [ 0.49830204  0.50169796]\n",
      " [ 0.41053769  0.58946228]\n",
      " [ 0.43988213  0.56011784]\n",
      " [ 0.45134884  0.5486511 ]\n",
      " [ 0.45840886  0.54159111]\n",
      " [ 0.45484114  0.54515892]\n",
      " [ 0.35959238  0.64040756]\n",
      " [ 0.38463753  0.61536252]\n",
      " [ 0.43728611  0.56271392]\n",
      " [ 0.42042059  0.57957947]\n",
      " [ 0.42697302  0.57302701]\n",
      " [ 0.40380016  0.59619981]\n",
      " [ 0.4389177   0.5610823 ]\n",
      " [ 0.4471567   0.55284327]\n",
      " [ 0.40085995  0.59914005]\n",
      " [ 0.42930827  0.5706917 ]\n",
      " [ 0.37276626  0.62723368]\n",
      " [ 0.48991904  0.51008099]\n",
      " [ 0.42652988  0.57347012]\n",
      " [ 0.44690952  0.55309051]\n",
      " [ 0.42610797  0.573892  ]\n",
      " [ 0.422667    0.57733297]\n",
      " [ 0.5060392   0.49396083]\n",
      " [ 0.46529013  0.53470981]\n",
      " [ 0.38167274  0.61832732]\n",
      " [ 0.52450401  0.47549602]\n",
      " [ 0.49523816  0.50476187]\n",
      " [ 0.45669958  0.54330039]\n",
      " [ 0.43819147  0.56180859]\n",
      " [ 0.48648679  0.51351327]\n",
      " [ 0.40479472  0.59520531]\n",
      " [ 0.38844395  0.61155605]\n",
      " [ 0.44341764  0.55658239]\n",
      " [ 0.40520915  0.59479088]\n",
      " [ 0.44724882  0.55275124]\n",
      " [ 0.45032638  0.54967356]\n",
      " [ 0.5145362   0.48546383]\n",
      " [ 0.50185174  0.49814826]\n",
      " [ 0.43350679  0.56649321]\n",
      " [ 0.42634711  0.57365292]\n",
      " [ 0.42689216  0.5731079 ]\n",
      " [ 0.47475594  0.52524406]\n",
      " [ 0.52452177  0.47547823]\n",
      " [ 0.36536807  0.63463193]\n",
      " [ 0.40288788  0.59711206]\n",
      " [ 0.43959528  0.56040472]\n",
      " [ 0.49547613  0.50452387]\n",
      " [ 0.44954658  0.55045348]\n",
      " [ 0.39267853  0.60732156]\n",
      " [ 0.43841845  0.56158149]\n",
      " [ 0.4129394   0.58706057]\n",
      " [ 0.40064567  0.59935427]\n",
      " [ 0.44034582  0.55965418]\n",
      " [ 0.35400581  0.64599419]\n",
      " [ 0.38439038  0.61560959]\n",
      " [ 0.44799381  0.55200624]\n",
      " [ 0.42458189  0.57541817]\n",
      " [ 0.41232657  0.58767343]\n",
      " [ 0.49562091  0.50437909]\n",
      " [ 0.41111568  0.58888423]\n",
      " [ 0.39363626  0.60636371]\n",
      " [ 0.41374397  0.58625603]\n",
      " [ 0.46085531  0.53914469]\n",
      " [ 0.41273794  0.58726203]\n",
      " [ 0.42243573  0.57756424]\n",
      " [ 0.52954316  0.47045681]\n",
      " [ 0.44054157  0.55945843]\n",
      " [ 0.39754003  0.60245997]\n",
      " [ 0.4355042   0.56449574]\n",
      " [ 0.45480192  0.54519814]\n",
      " [ 0.40660232  0.59339768]\n",
      " [ 0.46170852  0.53829151]\n",
      " [ 0.39977297  0.60022706]\n",
      " [ 0.44823387  0.5517661 ]\n",
      " [ 0.47158185  0.52841812]\n",
      " [ 0.47721395  0.52278608]\n",
      " [ 0.45564157  0.54435843]\n",
      " [ 0.37509626  0.62490374]\n",
      " [ 0.40096676  0.5990333 ]\n",
      " [ 0.36937276  0.63062721]\n",
      " [ 0.4434301   0.55656987]\n",
      " [ 0.34260556  0.65739441]\n",
      " [ 0.43775848  0.56224155]\n",
      " [ 0.36422464  0.63577533]\n",
      " [ 0.40234986  0.59765017]\n",
      " [ 0.43538937  0.56461066]\n",
      " [ 0.40417075  0.59582925]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.39357427  0.60642576]\n",
      " [ 0.40649131  0.59350872]\n",
      " [ 0.43921101  0.56078905]]\n",
      "Epoch: 1/1000,   Iteration: 20,   Train loss: 0.725,   10.3s /batch.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4268052   0.5731948 ]\n",
      " [ 0.49237293  0.50762713]\n",
      " [ 0.46678546  0.53321445]\n",
      " [ 0.48600188  0.51399815]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49635103  0.503649  ]\n",
      " [ 0.45010227  0.54989773]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49452868  0.50547135]\n",
      " [ 0.42807806  0.57192194]\n",
      " [ 0.45400646  0.54599351]\n",
      " [ 0.43918976  0.56081021]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.45937946  0.54062057]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.45231262  0.54768735]\n",
      " [ 0.49819168  0.50180829]\n",
      " [ 0.48395663  0.51604342]\n",
      " [ 0.46865734  0.53134263]\n",
      " [ 0.48504993  0.51495004]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49938598  0.50061399]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.41478732  0.58521277]\n",
      " [ 0.46104234  0.53895772]\n",
      " [ 0.44309774  0.55690223]\n",
      " [ 0.39661098  0.60338908]\n",
      " [ 0.44659916  0.55340087]\n",
      " [ 0.49510723  0.50489271]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.46369955  0.53630048]\n",
      " [ 0.49917448  0.50082552]\n",
      " [ 0.49833164  0.50166839]\n",
      " [ 0.45746255  0.54253745]\n",
      " [ 0.48704383  0.5129562 ]\n",
      " [ 0.46235642  0.53764355]\n",
      " [ 0.44269738  0.55730259]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.40121648  0.59878349]\n",
      " [ 0.43023661  0.56976348]\n",
      " [ 0.46789271  0.53210729]\n",
      " [ 0.49808526  0.50191474]\n",
      " [ 0.49912614  0.50087392]\n",
      " [ 0.46304438  0.53695565]\n",
      " [ 0.41563085  0.58436918]\n",
      " [ 0.45882735  0.54117268]\n",
      " [ 0.44083285  0.55916709]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.44843534  0.55156469]\n",
      " [ 0.42894685  0.57105315]\n",
      " [ 0.48769447  0.5123055 ]\n",
      " [ 0.43998507  0.5600149 ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49082601  0.50917399]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.46594262  0.53405744]\n",
      " [ 0.48679388  0.51320606]\n",
      " [ 0.47929099  0.52070898]\n",
      " [ 0.42916754  0.57083249]\n",
      " [ 0.46678573  0.53321421]\n",
      " [ 0.48679632  0.51320362]\n",
      " [ 0.46543363  0.53456628]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.4123165   0.5876835 ]\n",
      " [ 0.45428535  0.54571462]\n",
      " [ 0.48454025  0.51545978]\n",
      " [ 0.49005026  0.50994968]\n",
      " [ 0.48541987  0.51458013]\n",
      " [ 0.48833412  0.51166588]\n",
      " [ 0.46534029  0.53465968]\n",
      " [ 0.453693    0.54630703]\n",
      " [ 0.42770216  0.57229787]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.48563379  0.51436627]\n",
      " [ 0.4358854   0.56411463]\n",
      " [ 0.46029031  0.53970975]\n",
      " [ 0.47196558  0.52803439]\n",
      " [ 0.48535982  0.51464015]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.43911567  0.5608843 ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.41318142  0.58681858]\n",
      " [ 0.45636058  0.54363942]\n",
      " [ 0.43353197  0.56646806]\n",
      " [ 0.48981205  0.51018798]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.47588259  0.52411741]]\n",
      "[[ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.46377203  0.536228  ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.49611393  0.50388604]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.47421131  0.52578872]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]]\n",
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "Epoch: 2/1000,   Iteration: 25,   Train loss: 0.693,   10.5s /batch.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ddd264f3ad21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                                   num_layers=num_layers, learning_rate=lr, grad_clip=0.5)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-1bfa8c5ef747>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, file_writer, save_string)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#                 print(model.outputs_1.shape, model.outputs_1[:, -1], model.final_output_concat,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#                       model.logits, model.predictions, model.cost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#                 print('pred: {}'.format(type(pred)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/congcong/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/congcong/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/congcong/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/congcong/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/congcong/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 100\n",
    "for lstm_size in [2000]:\n",
    "    for num_layers in [1]:\n",
    "        for lr in [0.0003]:\n",
    "                log_string = 'logs/4/lr={},nl={},ls={},bs={}'.format(lr, num_layers, lstm_size, batch_size)\n",
    "                save_string = 'checkpoints\\lr={}_nl={}_ls={}_bs={}.ckpt'.format(lr, num_layers, lstm_size, batch_size)\n",
    "                \n",
    "                writer = tf.summary.FileWriter(log_string)\n",
    "\n",
    "                model = build_rnn(batch_size=batch_size, lstm_size=lstm_size, \n",
    "                                  num_layers=num_layers, learning_rate=lr, grad_clip=0.6)\n",
    "\n",
    "                train(model, epochs, writer, save_string)\n",
    "                \n",
    "                print(' ')\n",
    "                print(' ')\n",
    "                print(\"leraning_rate={},num_layers={},lstm_size={},batch_size={} finished, saved\".format(lr, num_layers, lstm_size, batch_size))\n",
    "                print(' ')\n",
    "                print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
